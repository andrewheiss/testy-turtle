{
  "hash": "f015a9b60d53fbc36e5caa54b61898c0",
  "result": {
    "markdown": "---\ntitle: \"Working with tricky outcomes with lots of zeros\"\nformat:\n  html:\n    toc-depth: 5\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(targets)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(scales)\nlibrary(patchwork)\nlibrary(ggtext)\nlibrary(ggh4x)\nlibrary(kableExtra)\nlibrary(broom.mixed)\nlibrary(marginaleffects)\nlibrary(extraDistr)\n\ntar_config_set(store = here::here('_targets'),\n               script = here::here('_targets.R'))\n\nset.seed(1234)\n\n# Load stuff from targets\n# Plotting functions\ninvisible(list2env(tar_read(graphic_functions), .GlobalEnv))\n\ntar_load(c(m_oda_prelim_time_only_total, m_purpose_prelim_time_only_total))\n\ndf_country_aid <- tar_read(country_aid_final)\ndf_country_aid_laws <- filter(df_country_aid, laws)\n\n# Tell bayesplot to use the sunset palette for things like pp_check()\nbayesplot::color_scheme_set(clrs$Sunset[2:7])\n```\n:::\n\n\n# Complex models\n\nThroughout this project, we use more complex Bayesian models (multilevel hurdle models and zero-inflated models) instead of basic OLS because the data we're working with is more complex. The complexity in the data leads to complexity in the models, which leads to complexity in the code. Keeping track of and working with all the different moving parts of these models is tricky. As Richard McElreath says, \n\n> [A]s models become more monstrous, so too does the code needed to compute predictions and display them. **With power comes hardship.** It's better to see the guts of the machine than to live in awe or fear of it. [@McElreath:2020, 391]\n\nThis document is a basic guide showcasing the entire complexity of the hurdle and zero-inflated models, walking through their formal specifications, how specify priors, how to fit the models and extract posteriors, and how to analyze the posteriors at a population-level and group-level for all the different portions (i.e. non-zero vs. zero) of these models. This document is not our actual analysis—for the sake of simplicity, we only illustrate the effect of year on our outcomes, like `outcome ~ year + (1 + year | country)`. Instead, this document is an illustration and reference for ourselves.\n\n\n# The problem with zeros\n\nAll of our outcome variables have a substantial and nontrivial number of zeros in them:\n\n\n::: {#tbl-zero-summary .cell layout-align=\"center\" tbl-cap='0s in our main outcome variables'}\n\n```{.r .cell-code}\nbind_rows(\n  `Total ODA (H1)` = count(df_country_aid_laws, is_zero = total_oda == 0),\n  `Proportion of contentious aid (H2)` = count(df_country_aid_laws, is_zero = prop_contentious == 0),\n  `Proportion of aid to domestic NGOs (H3)` = count(df_country_aid_laws, is_zero = prop_ngo_dom == 0),\n  `Proportion of aid to foreign NGOs (H3)` = count(df_country_aid_laws, is_zero = prop_ngo_foreign == 0),\n  .id = \"Outcome\"\n) %>% \n  group_by(Outcome) %>% \n  mutate(`Number of 0s` = glue::glue(\"{n[2]} / {sum(n)}\")) %>% \n  mutate(`Proportion of 0s` = label_percent(accuracy = 0.1)(n / sum(n))) %>% \n  ungroup() %>% \n  filter(is_zero) %>% select(-is_zero, -n) %>% \n  kbl(align = c(\"l\", \"c\", \"c\")) %>% \n  kable_styling(htmltable_class = \"table table-sm\",\n                full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" table table-sm\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Outcome </th>\n   <th style=\"text-align:center;\"> Number of 0s </th>\n   <th style=\"text-align:center;\"> Proportion of 0s </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Total ODA (H1) </td>\n   <td style=\"text-align:center;\"> 198 / 3293 </td>\n   <td style=\"text-align:center;\"> 6.0% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Proportion of contentious aid (H2) </td>\n   <td style=\"text-align:center;\"> 479 / 3293 </td>\n   <td style=\"text-align:center;\"> 14.5% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Proportion of aid to domestic NGOs (H3) </td>\n   <td style=\"text-align:center;\"> 1452 / 3293 </td>\n   <td style=\"text-align:center;\"> 44.1% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Proportion of aid to foreign NGOs (H3) </td>\n   <td style=\"text-align:center;\"> 1384 / 3293 </td>\n   <td style=\"text-align:center;\"> 42.0% </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nHere's what that looks like with foreign aid:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_dist_unlogged <- df_country_aid_laws %>%\n  mutate(is_zero = total_oda == 0) %>% \n  mutate(total_oda = ifelse(is_zero, -0.1, total_oda))  %>%  \n  ggplot(aes(x = total_oda)) +\n  geom_histogram(aes(fill = is_zero), binwidth = 2e9, \n                 linewidth = 0.25, boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) + \n  scale_x_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n  scale_y_continuous(labels = label_comma()) +\n  scale_fill_manual(values = c(clrs$Prism[2], clrs$Prism[8]), \n                    guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Total ODA\", y = \"Count\", fill = \"Is zero?\",\n       subtitle = \"Nice and exponentially shaped,\\nwith a bunch of zeros\") +\n  theme_donors() +\n  theme(legend.position = \"bottom\")\n\nplot_dist_logged <- df_country_aid_laws %>%\n  mutate(is_zero = total_oda_log == 0) %>% \n  mutate(total_oda_log = ifelse(is_zero, -0.1, total_oda_log))  %>%  \n  ggplot(aes(x = total_oda_log)) +\n  geom_histogram(aes(fill = is_zero), binwidth = 1, \n                 linewidth = 0.25, boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) +\n  scale_x_continuous(labels = label_math(e^.x)) +\n  scale_fill_manual(values = c(clrs$Prism[2], clrs$Prism[8]), \n                    guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Total ODA\", y = \"Count\", fill = \"Is zero?\",\n       subtitle = \"Nice and normally shaped, with a bunch of zeros;\\nit's hard to interpret intuitively though\") +\n  theme_donors() +\n  theme(legend.position = \"bottom\")\n\n(plot_dist_unlogged | plot_dist_logged) +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(title = \"ODA, original vs. logged\",\n                  theme = theme(plot.title = element_text(family = \"Inter\", face = \"bold\"),\n                                legend.position = \"bottom\"))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zero-oda-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nAnd with the proportion variables:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- df_country_aid_laws %>%\n  mutate(is_zero = prop_contentious == 0) %>% \n  mutate(prop_contentious = ifelse(is_zero, -0.05, prop_contentious))  %>%  \n  ggplot(aes(x = prop_contentious)) +\n  geom_histogram(aes(fill = is_zero), binwidth = 0.05, \n                 linewidth = 0.25, boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) + \n  scale_x_continuous(labels = label_percent()) +\n  scale_y_continuous(labels = label_comma()) +\n  scale_fill_manual(values = c(clrs$Prism[2], clrs$Prism[8]), \n                    guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Proportion of contentious aid\", y = \"Count\", fill = \"Is zero?\") +\n  coord_cartesian(ylim = c(0, 1500)) +\n  theme_donors() +\n  theme(legend.position = \"bottom\")\n\np2 <- df_country_aid_laws %>%\n  mutate(is_zero = prop_ngo_dom == 0) %>% \n  mutate(prop_ngo_dom = ifelse(is_zero, -0.05, prop_ngo_dom))  %>%  \n  ggplot(aes(x = prop_ngo_dom)) +\n  geom_histogram(aes(fill = is_zero), binwidth = 0.05, \n                 linewidth = 0.25, boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) + \n  scale_x_continuous(labels = label_percent()) +\n  scale_y_continuous(labels = label_comma()) +\n  scale_fill_manual(values = c(clrs$Prism[2], clrs$Prism[8]), \n                    guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Proportion of aid to domestic NGOs\", y = NULL, fill = \"Is zero?\") +\n  coord_cartesian(ylim = c(0, 1500)) +\n  theme_donors() +\n  theme(legend.position = \"bottom\")\n\np3 <- df_country_aid_laws %>%\n  mutate(is_zero = prop_ngo_foreign == 0) %>% \n  mutate(prop_ngo_foreign = ifelse(is_zero, -0.05, prop_ngo_foreign))  %>%  \n  ggplot(aes(x = prop_ngo_foreign)) +\n  geom_histogram(aes(fill = is_zero), binwidth = 0.05, \n                 linewidth = 0.25, boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) + \n  scale_x_continuous(labels = label_percent()) +\n  scale_y_continuous(labels = label_comma()) +\n  scale_fill_manual(values = c(clrs$Prism[2], clrs$Prism[8]), \n                    guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Proportion of aid to foreign NGOs\", y = NULL, fill = \"Is zero?\") +\n  coord_cartesian(ylim = c(0, 1500)) +\n  theme_donors() +\n  theme(legend.position = \"bottom\")\n\n(p1 | p2 | p3) +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(title = \"Proportion-based outcomes\",\n                  theme = theme(plot.title = element_text(family = \"Inter\", face = \"bold\"),\n                                legend.position = \"bottom\"))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zero-props-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n# Hurdle vs. zero-inflated models\n\nThese zeros pose a whole host of tricky methodological issues. We could be like economists and just throw OLS at all these, or do what we've done in past versions of this paper and just use OLS on logged aid and fractional logit stuff for the proportions, but we can do better—we can model the zeros directly!\n\nIn the course of working on this paper, I've written a couple complete guides (for future-me, who is now present-me!) about two different approaches for doing this:\n\n- [Guide for hurdle models](https://www.andrewheiss.com/blog/2022/05/09/hurdle-lognormal-gaussian-brms/) (for total ODA)\n- [Guide for zero-inflated models](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/) (for proportions)\n\nThere's actually a subtle difference between hurdle models and zero-inflated models, and [this Stack Exchange answer explains the distinction exceptionally well](https://stats.stackexchange.com/questions/81457/what-is-the-difference-between-zero-inflated-and-hurdle-models).\n\nPut simply, in hurdle models there's only one way to get a zero in the outcome; in zero-inflated models there are two ways to get a zero in the outcome. Both models use a two-step process:\n\n1. In the first stage for both types of models, we model if an outcome is either zero or not zero, or if the non-zero data generating process is on or off. It has a probability $\\pi$ of being off (or 0) and a probability $1 - \\pi$ of being on (or 1)\n\n2. In the second stage, the two models diverge a little\n\n   a. For hurdle models, there is only one way to get a zero, which is handled with the $\\pi$ part in the first stage. Predicted values of $y$ in this second stage cannot be zero, so the distribution of $y$ is truncated at $y > 0$. This is done with some fancy math that incorporates the probability of being not zero ($1 - \\pi$) and the regular distribution family (Poisson, lognormal, whatever):\n\n      $$\n      \\begin{aligned}\n      & \\textbf{Hurdle log-normal observation model} \\\\\n      y &\\sim \\operatorname{Hurdle\\,log-normal}(\\mu, \\sigma, \\pi) \\quad \\text{or alternatively,}\\\\\n      y &\\sim \\begin{cases}\n      0 & \\text{with probability } \\pi \\\\\n      \\operatorname{Log-normal}(\\mu, \\sigma) & \\text{with probability } 1 - \\pi\n      \\end{cases} \\\\[4pt]\n      \\operatorname{logit}(\\pi) &= \\gamma_0 + \\gamma_1 x_1 \\\\\n      \\log(\\mu) &= \\beta_0 + \\beta_1 x_1 \\\\\n      \\sigma &\\sim \\operatorname{Exponential}(1) \\\\[10pt]\n      & \\textbf{Likelihood of zero} \\\\\n      \\Pr(0 \\mid \\pi) &= \n      \\underbracket[0.25pt]{\\Pr(\\text{No $y$} \\mid \\pi)}_{\\substack{\\text{Probability}\\\\ \\text{of no $y$}}}\\ =\\ \\pi \\\\[10pt]\n      & \\textbf{Hurdle log-normal likelihood} \\\\\n      \\Pr(y \\mid \\pi, \\mu, \\sigma) &=\n      \\begin{dcases}\n      \\pi & \\text{if } y = 0 \\\\[4pt]\n      \\underbracket[0.25pt]{\\frac{(1 - \\pi) \\times \\operatorname{Log-normal}(y \\mid \\mu, \\sigma)}\n      {1 - \\operatorname{Log-normal}(0 \\mid \\mu, \\sigma)}}_{\\text{Will only predict $y > 0$}} & \\text{if } y > 0\n      \\end{dcases}\n      \\end{aligned}\n      $$\n\n   b. For zero-inflated models, there are two ways to get a zero. For example, in [section 12.2 in *Statistical Rethinking*](https://bookdown.org/content/4857/monsters-and-mixtures.html#example-zero-inflated-poisson.), @McElreath:2020 gives an example of monks who can either (1) drink and do no work, or (2) work and transcribe some number of manuscripts. There's a two-stage process for getting possible 0s here. A monk could transcribe 0 manuscripts because of the $\\pi$ on/off process in the first stage (e.g., they decide to drink and not even attempt to copy any manuscripts). Alternatively, the monk could be \"on\" in the first stage (e.g., they decide to not drink and to work instead), but then they don't end up transcribing anything (e.g., the final count is 0 because they were slow, lazy, had a difficult manuscript, or whatever).\n   \n      So we have to incorporate both avenues for getting a 0 into the likelihood for zero. Predicted values of $y$ in this stage *can* be zero, so unlike hurdle models, this isn't truncated or anything. We use some distribution family (Poisson, negative binomial, beta, whatever) at this stage and generate predictions where $y \\geq 0$.\n   \n      SUPER WEIRDLY THOUGH, despite its name, zero-inflated Beta regression [is actually kinda sorta a hurdle model and not a zero-inflated model](https://stats.stackexchange.com/a/81854/3025) because $\\operatorname{Beta}(0 \\mid \\mu, \\phi)$ isn't normally allowed since the Beta distribution typically only covers $0 < y < 1$ or (0, 1) rather than [0, 1]. That is, according to this definition of hurdling vs. zero-inflating, in zero-inflated models zero is still a possible outcome after moving past the first zero/not zero stage, but the Beta distribution typically doesn't allow for zeros. ::huge-shrug::\n   \n      $$\n      \\begin{aligned}\n      & \\textbf{Zero-inflated Beta observation model} \\\\\n      y &\\sim \\operatorname{Zero-inflated\\, Beta}(\\pi, \\mu, \\phi) \\quad \\text{or alternatively,}\\\\\n      y &\\sim \\begin{cases}\n      0 & \\text{with probability } \\pi + [(1 - \\pi) \\times \\operatorname{Beta}(0 \\mid \\mu, \\phi)] \\\\\n      \\operatorname{Beta}(\\mu, \\phi) & \\text{with probability } (1 - \\pi) \\times \\operatorname{Beta}(y \\mid \\mu, \\phi)\n      \\end{cases} \\\\[4pt]\n      \\operatorname{logit}(\\pi) &= \\gamma_0 + \\gamma_1 x_1 \\\\\n      \\operatorname{logit}(\\mu) &= \\beta_0 + \\beta_1 x_1 \\\\\n      \\phi &\\sim \\operatorname{Exponential}(1) \\\\[10pt]\n      & \\textbf{Likelihood of zero} \\\\\n      \\Pr(0 \\mid \\pi, \\mu, \\phi) &= \n      \\underbracket[0.25pt]{\\Pr(\\text{No $y$} \\mid \\pi)}_{\\substack{\\text{Probability of} \\\\ \\text{no $y$ at all}}} \n      \\ \\overbracket[0.25pt]{+}^{\\text{or}}\\ \n      \\underbracket[0.25pt]{\\left[\\Pr(\\text{Yes $y$} \\mid \\pi) \\times \\Pr(0 \\mid \\mu, \\phi)\\right]}_{\\substack{\\text{Probability of yes $y$,} \\\\ \\text{but it happens to be 0}}} \\\\\n      &= \\pi + [(1 - \\pi) \\times \\operatorname{Beta}(0 \\mid \\mu, \\phi)] \\\\[10pt]\n      & \\textbf{Zero-inflated Beta likelihood} \\\\\n      \\Pr(y \\mid \\pi, \\mu, \\phi) &=\n      \\begin{cases}\n      \\pi + [(1 - \\pi) \\times \\operatorname{Beta}(0 \\mid \\mu, \\phi)] & \\text{if } y = 0 \\\\[4pt]\n      \\underbracket[0.25pt]{(1 - \\pi) \\times \\operatorname{Beta}(y \\mid \\mu, \\phi)}_{\\text{Will predict $y \\geq 0$}} & \\text{if } y > 0\n      \\end{cases}\n      \\end{aligned}\n      $$\n\nWith all that… whatever. This difference doesn't super matter for us here. We'll use both of these kinds of families to model our zero-heavy outcomes.\n\n::: {.callout-tip}\n### More complete documentation\n\nFiguring out all this model and likelihood stuff for hurdle and zero-inflated regression has been really tricky and nuanced and I'm still not 100% sure this is 100% accurate. But thanks to some fantastic help from people on Twitter and Mastodon, I got this far! Here are some of the resources I used for all this:\n\n- [Aki Vehtari's Mastodon thread](https://bayes.club/@avehtari/109382966876733736) on the differences between likelihoods and distributions, and models. He proposes calling the whole complex formal hierarchical model a \"statistical model\" and calling the part that invovles observations an \"observation model\". He also distinguishes between (1) tilde notation ($y \\sim \\mathcal{N}(\\mu, \\sigma)$), which is read as \"y is distributed as normal(mu sigma),\" and which refers to the observation model, and (2) likelihood notation ($\\Pr(y \\mid \\theta)$), which can either be a distribution or a likelihood, resulting in all sorts of confusion.\n\n- The [brms vignette on zero-inflated and hurdle models](https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html#zero-inflated-and-hurdle-models) defines the likelihood of both kinds of models in general mathy terms, where $z$ is the zero-inflation probability and $f(\\cdot)$ is the family for the second stage:\n\n  - Zero-inflated density:\n\n    $$\n    f_z(y) = \n    \\begin{cases}\n    z + (1 - z) f(0) & \\text{if } y = 0 \\\\\n    (1 - z) f(y) & \\text{if } y > 0\n    \\end{cases}\n    $$\n  \n  - Hurdle density:\n\n    $$\n    f_z(y) = \\begin{cases}\n    z & \\text{if } y = 0 \\\\\n    (1 - z) f(y) / (1 - f(0)) & \\text{if } y > 0\n    \\end{cases}\n    $$\n\n- [The Stan documentation for zero inflation](https://mc-stan.org/docs/stan-users-guide/zero-inflated.html) shows the same thing, with slightly different notation. It also shows the actual Stan code necessary for these kinds of models.\n\n- Sections 12.4.1 and 12.4.2 in @Frees:2009 ([copy here](https://finance.nankai.edu.cn/_upload/article/files/c6/44/73f40f574e069868d74d52345ece/69e1f4b9-4aa4-48d2-8c63-3e205e73c749.pdf)) provide a similar overview and slightly different notation for both kinds of models.\n\n:::\n\n\n# Hurdle models (total aid)\n\nWe're not entirely sure what the actual underlying zero process is for foreign aid, but from looking at the data, we know that there's a time component—before 1995 and after 2005 lots of countries received no aid. We don't know why, though. Maybe there are issues with reporting quality. Maybe some countries didn't need aid anymore (almost like a survival model, but not really, since countries can resume getting aid later after seeing a 0). Maybe there were political reasons. It's impossible to tell, and it goes beyond the scope of our paper here. \n\nWe can see the year-based differences in the presence/absence of 0s in this plot here, with a few countries highlighted to show possible trajectories over time: Georgia starting with 0s then rising to regular levels of aid; Trinidad and Tobago starting with regular levels of aid and then dropping to 0s; Estonia starting with regular levels of aid and then dropping to 0, then resuming aid, then dropping to 0s again.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_hurdle_highlight <- df_country_aid_laws %>% \n  mutate(highlight_country = ifelse(country %in% c(\"Estonia\", \"Georgia\", \"Trinidad & Tobago\"), \n                                    country, \"Other\"),\n         highlight_country = factor(highlight_country, ordered = TRUE),\n         highlight_country = fct_relevel(highlight_country, \"Other\", after = Inf)) %>% \n  mutate(highlight = highlight_country != \"Other\")\n\ndf_hurdle_highlight %>% \n  ggplot(aes(x = year, y = total_oda, group = country, \n             color = highlight_country, linewidth = highlight)) +\n  geom_line() +\n  scale_y_continuous(trans = \"log1p\", breaks = c(0, 1e5, 1e8, 1e11),\n                     labels = label_dollar(scale_cut = cut_short_scale())) +\n  scale_color_manual(values = c(clrs$Prism[2], clrs$Prism[7], clrs$Prism[9], \"grey50\")) +\n  scale_linewidth_discrete(range = c(0.075, 1.25), guide = \"none\") +\n  labs(x = NULL, y = \"Total ODA (logged)\", color = NULL) +\n  guides(color = guide_legend(override.aes = list(linewidth = 1))) +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-oda-over-time-highlight-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nThe time trend is even clearer if we plot the proportion of zeros in each year. It actually fits a 2nd-degree polynomial trend really well, but for the sake of simplicity in this example, we'll just model it as linear and not include a squared term. In our actual models, we use year² in the hurdle part of the model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_country_aid_laws %>% \n  group_by(year) %>% \n  summarize(prop_zero = mean(total_oda == 0)) %>% \n  ggplot(aes(x = year, y = prop_zero)) +\n  geom_line(linewidth = 0.5, color = \"grey70\") +\n  geom_point(size = 1) + \n  geom_smooth(aes(color = \"y = x\"), method = \"lm\", \n              formula = y ~ x, se = FALSE) +\n  geom_smooth(aes(color = \"y = x + x<sup>2</sup>\"), method = \"lm\", \n              formula = y ~ x + I(x^2), se = FALSE) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_color_manual(values = clrs$Prism[c(3, 11)]) +\n  labs(x = NULL, y = \"Proportion of countries with zero ODA\",\n       color = NULL) +\n  theme_donors() +\n  theme(legend.text = element_markdown())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-prop-zero-hu-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Formal statistical model\n\nTo account for these dips into 0, we'll use a hurdle lognormal family (since ODA is exponentially distributed) with a multilevel hierarchical model with country-specific intercepts and a year trend with country-specific offsets (following yet another guide I wrote for this project, [this one on multilevel panel data](https://www.andrewheiss.com/blog/2021/12/01/multilevel-models-panel-data-guide/)). \n\nWe center the year at 2000 so that (1) the intercept is interpretable [@Schielzeth:2010] and (2) the MCMC simulation runs faster and more efficiently [@McElreath:2020 §13.4, pp. 420–422].\n\nIn the actual models we run we include treatment history, independent variables related to civil society, and inverse probability weights, but here since we're just exploring the mechanics of multilevel hurdle models, we use just a country-and-year-only model.\n\nIn {brms}'s [random effects syntax](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification), the model formula looks like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nbf(total_oda ~ year_c + (1 + year_c | gwcode),\n   hu ~ year_c)\n```\n:::\n\n\n@eq-hurdle-baseline shows this in more formal mathematical notation, with all the different random effects offsets and priors all working together simultaneously:\n\n::: {.column-page-inset-right}\n\n$$\n\\begin{aligned}\n& \\mathrlap{\\textbf{Hurdled model of aid $i$ across time $t$ within each country $j$}} \\\\\n\\text{Foreign aid}_{it_j} &\\sim \\mathrlap{\\operatorname{Hurdle\\,log-normal}(\\pi_{it}, \\mu_{it_j}, \\sigma_y) \\quad \\text{or alternatively,}} \\\\\n\\text{Foreign aid}_{it_j} &\\sim \\mathrlap{\\begin{cases}\n0 & \\text{with probability } \\pi_{it} \\\\[4pt]\n\\operatorname{Log-normal}(\\mu_{it_j}, \\sigma_y) & \\text{with probability } 1 - \\pi_{it}\n\\end{cases}} \\\\\n\\\\\n& \\textbf{Models for distribution parameters} \\\\\n\\operatorname{logit}(\\pi_{it}) &= \\gamma_0 + \\gamma_1 \\text{Year}_{it} & \\text{Zero/not-zero process} \\\\[4pt]\n\\log (\\mu_{it_j}) &= (\\beta_0 + b_{0_j}) + (\\beta_1 + b_{1_j}) \\text{Year}_{it_j} & \\text{Within-country variation} \\\\[4pt]\n\\left(\n  \\begin{array}{c} \n  b_{0_j} \\\\\n  b_{1_j}\n  \\end{array}\n\\right) \n&\\sim \\text{MV}\\,\\mathcal{N}\n\\left[\n  \\left(\n    \\begin{array}{c}\n    0 \\\\\n    0 \\\\\n    \\end{array}\n  \\right)\n  , \\,\n  \\left(\n  \\begin{array}{cc}\n     \\sigma^2_{0} & \\rho_{0, 1}\\, \\sigma_{0} \\sigma_{1} \\\\ \n     \\cdots & \\sigma^2_{1}\n  \\end{array}\n\\right)\n\\right] & \\text{Variability in average intercepts and slopes} \\\\\n\\\\\n& \\textbf{Priors} \\\\\n\\gamma_0 &\\sim \\text{Student $t$}(3, -2, 1.5) & \\text{Prior for intercept in hurdle model} \\\\\n\\gamma_1 &\\sim \\text{Student $t$}(3, 0, 1.5) & \\text{Prior for year effect in hurdle model} \\\\\n\\beta_0 &\\sim \\mathcal{N}(20, 2.5) & \\text{Prior for global average aid} \\\\\n\\beta_1 &\\sim \\mathcal{N}(0, 2) & \\text{Prior for global year effect} \\\\\n\\sigma_y &\\sim \\operatorname{Exponential}(1) & \\text{Prior for within-country variability} \\\\\n\\sigma_0 &\\sim \\operatorname{Exponential}(1) & \\text{Prior for between-country intercept variability} \\\\\n\\sigma_1 &\\sim \\operatorname{Exponential}(1) & \\text{Prior for between-country slope variability} \\\\\n\\rho &\\sim \\operatorname{LKJ}(2) & \\text{Prior for between-country variability}\n\\end{aligned}\n$$ {#eq-hurdle-baseline}\n\n:::\n\n## Prior simulation\n\nFor this year-and-country-only model, we set the following priors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndesign <- \"\n  AAABBB\n  CCCDDD\n  EEFFGG\n\"\n\nm_oda_prelim_time_only_total$priors %>% \n  parse_dist() %>% \n  # K = dimension of correlation matrix; \n  # ours is 2x2 here because we have one random slope\n  marginalize_lkjcorr(K = 2) %>%\n  mutate(nice_title = glue::glue(\"**{class}**: {prior}\"),\n         stage = ifelse(dpar == \"hu\", \"Hurdle part (π)\", \"Lognormal part (µ and σ)\")) %>% \n  mutate(nice_title = fct_inorder(nice_title)) %>% \n  ggplot(aes(y = 0, dist = .dist, args = .args, fill = prior)) +\n  stat_slab(normalize = \"panels\") +\n  scale_fill_manual(values = clrs$Prism[1:6]) +\n  facet_manual(vars(stage, nice_title), design = design, scales = \"free_x\",\n               strip = strip_nested(background_x = list(element_rect(fill = \"grey92\"), NULL),\n                                    by_layer_x = TRUE)) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = NULL) +\n  theme_donors(prior = TRUE) +\n  theme(strip.text = element_markdown())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hurdle-priors-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nTo make sure these are somewhat reasonable priors, we simulate from them exclusively (following the process outlined in both [*Statistical Rethinking*](https://xcelab.net/rm/statistical-rethinking/) and [*Bayes Rules!*](https://www.bayesrulesbook.com/)). Some of these are wild and go into the trillions, but in general they're in the hundreds-of-millions-of-dollars range, which is good. \n\nThese'll do.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_country_aid_laws %>%  \n  add_epred_draws(m_oda_prelim_time_only_total$model_prior_only, ndraws = 9,\n                  seed = 12345) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .epred, group = paste(gwcode, .draw))) +\n  geom_line(linewidth = 0.15, color = clrs$Prism[8]) +\n  scale_y_log10(labels = label_dollar(scale_cut = cut_short_scale())) +\n  coord_cartesian(ylim = c(1e3, 5e11)) +\n  facet_wrap(vars(.draw)) +\n  labs(x = \"Year\", y = \"Foreign aid\", title = \"Results sampled from prior only\",\n       subtitle = \"Each panel shows plausible aid-year relationships for 142 simulated countries\") +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/prior-simulations-hurdle-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n## Posterior checks\n\n### MCMC diagnostics\n\n::: {.panel-tabset}\n\n#### Trace plots\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_oda_prelim_time_only_total$model %>% \n  gather_draws(`^b_.*|^sd_.*|^cor_.*|^sigma`, regex = TRUE) %>% \n  ggplot(aes(x = .iteration, y = .value, color = factor(.chain))) +\n  geom_line(size = 0.1) +\n  scale_color_manual(values = clrs$Sunset[3:6]) +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-trace-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n#### Trank plots\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_oda_prelim_time_only_total$model %>% \n  gather_draws(`^b_.*|^sd_.*|^cor_.*|^sigma`, regex = TRUE) %>% \n  group_by(.variable) %>% \n  mutate(draw_rank = rank(.value)) %>% \n  ggplot(aes(x = draw_rank, color = factor(.chain))) +\n  stat_bin(geom = \"step\", binwidth = 500, position = position_identity(), boundary = 0) +\n  scale_color_manual(values = clrs$Sunset[3:6]) +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme_donors() +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-trank-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n#### MCMC duration\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nrstan::get_elapsed_time(m_oda_prelim_time_only_total$model$fit)\n##         warmup sample\n## chain:1   31.0   72.8\n## chain:2   29.9   78.3\n## chain:3   28.9   65.8\n## chain:4   30.7   76.0\n\nrstan::get_elapsed_time(m_oda_prelim_time_only_total$model$fit) %>% \n  as.data.frame() %>% \n  summarize(longest = lubridate::as.duration(max(warmup + sample)))\n##                  longest\n## 1 108.19s (~1.8 minutes)\n```\n:::\n\n\n:::\n\n### Posterior predictive check\n\nLook at that—it all fits so nicely!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwithr::with_seed(1234, {\n  pp_check(m_oda_prelim_time_only_total$model, ndraws = 20) +\n    coord_cartesian(xlim = c(0, 1e10)) +\n    labs(x = \"Total ODA\", title = \"Hurdle lognormal model posterior predictive check\") +\n    scale_x_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n    theme_donors() +\n    theme(axis.text.y = element_blank())\n})\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-pp-check-hu-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Analyzing the posterior\n\nIn the actual paper we only interpret the treatment coefficient (total count of barriers, specific barriers, and V-Dem's civil society index), since that's all we can legally interpret when doing causal inference—we've only identified and closed off one pathway in the DAG, so all the other coefficients are incomplete [@WestreichGreenland:2013; @KeeleStevensonElwert:2020].\n\nThough we only really care about one effect here, we actually have a ton of different parameters to work with—300!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the full list of 300 things\"}\nget_variables(m_oda_prelim_time_only_total$model)\n##   [1] \"b_Intercept\"                   \"b_hu_Intercept\"                \"b_hu_year_c\"                  \n##   [4] \"b_year_c\"                      \"sd_gwcode__Intercept\"          \"sd_gwcode__year_c\"            \n##   [7] \"cor_gwcode__Intercept__year_c\" \"sigma\"                         \"r_gwcode[40,Intercept]\"       \n##  [10] \"r_gwcode[41,Intercept]\"        \"r_gwcode[42,Intercept]\"        \"r_gwcode[51,Intercept]\"       \n##  [13] \"r_gwcode[52,Intercept]\"        \"r_gwcode[70,Intercept]\"        \"r_gwcode[90,Intercept]\"       \n##  [16] \"r_gwcode[91,Intercept]\"        \"r_gwcode[92,Intercept]\"        \"r_gwcode[93,Intercept]\"       \n##  [19] \"r_gwcode[94,Intercept]\"        \"r_gwcode[95,Intercept]\"        \"r_gwcode[100,Intercept]\"      \n##  [22] \"r_gwcode[101,Intercept]\"       \"r_gwcode[110,Intercept]\"       \"r_gwcode[130,Intercept]\"      \n##  [25] \"r_gwcode[135,Intercept]\"       \"r_gwcode[140,Intercept]\"       \"r_gwcode[145,Intercept]\"      \n##  [28] \"r_gwcode[150,Intercept]\"       \"r_gwcode[155,Intercept]\"       \"r_gwcode[160,Intercept]\"      \n##  [31] \"r_gwcode[165,Intercept]\"       \"r_gwcode[235,Intercept]\"       \"r_gwcode[290,Intercept]\"      \n##  [34] \"r_gwcode[310,Intercept]\"       \"r_gwcode[316,Intercept]\"       \"r_gwcode[317,Intercept]\"      \n##  [37] \"r_gwcode[339,Intercept]\"       \"r_gwcode[341,Intercept]\"       \"r_gwcode[343,Intercept]\"      \n##  [40] \"r_gwcode[344,Intercept]\"       \"r_gwcode[345,Intercept]\"       \"r_gwcode[346,Intercept]\"      \n##  [43] \"r_gwcode[347,Intercept]\"       \"r_gwcode[349,Intercept]\"       \"r_gwcode[352,Intercept]\"      \n##  [46] \"r_gwcode[355,Intercept]\"       \"r_gwcode[359,Intercept]\"       \"r_gwcode[360,Intercept]\"      \n##  [49] \"r_gwcode[365,Intercept]\"       \"r_gwcode[366,Intercept]\"       \"r_gwcode[367,Intercept]\"      \n##  [52] \"r_gwcode[368,Intercept]\"       \"r_gwcode[369,Intercept]\"       \"r_gwcode[370,Intercept]\"      \n##  [55] \"r_gwcode[371,Intercept]\"       \"r_gwcode[372,Intercept]\"       \"r_gwcode[373,Intercept]\"      \n##  [58] \"r_gwcode[404,Intercept]\"       \"r_gwcode[411,Intercept]\"       \"r_gwcode[420,Intercept]\"      \n##  [61] \"r_gwcode[432,Intercept]\"       \"r_gwcode[433,Intercept]\"       \"r_gwcode[434,Intercept]\"      \n##  [64] \"r_gwcode[435,Intercept]\"       \"r_gwcode[436,Intercept]\"       \"r_gwcode[437,Intercept]\"      \n##  [67] \"r_gwcode[438,Intercept]\"       \"r_gwcode[439,Intercept]\"       \"r_gwcode[450,Intercept]\"      \n##  [70] \"r_gwcode[451,Intercept]\"       \"r_gwcode[452,Intercept]\"       \"r_gwcode[461,Intercept]\"      \n##  [73] \"r_gwcode[471,Intercept]\"       \"r_gwcode[475,Intercept]\"       \"r_gwcode[481,Intercept]\"      \n##  [76] \"r_gwcode[482,Intercept]\"       \"r_gwcode[484,Intercept]\"       \"r_gwcode[490,Intercept]\"      \n##  [79] \"r_gwcode[500,Intercept]\"       \"r_gwcode[501,Intercept]\"       \"r_gwcode[510,Intercept]\"      \n##  [82] \"r_gwcode[516,Intercept]\"       \"r_gwcode[517,Intercept]\"       \"r_gwcode[520,Intercept]\"      \n##  [85] \"r_gwcode[522,Intercept]\"       \"r_gwcode[530,Intercept]\"       \"r_gwcode[531,Intercept]\"      \n##  [88] \"r_gwcode[540,Intercept]\"       \"r_gwcode[541,Intercept]\"       \"r_gwcode[551,Intercept]\"      \n##  [91] \"r_gwcode[552,Intercept]\"       \"r_gwcode[553,Intercept]\"       \"r_gwcode[560,Intercept]\"      \n##  [94] \"r_gwcode[565,Intercept]\"       \"r_gwcode[570,Intercept]\"       \"r_gwcode[571,Intercept]\"      \n##  [97] \"r_gwcode[572,Intercept]\"       \"r_gwcode[580,Intercept]\"       \"r_gwcode[581,Intercept]\"      \n## [100] \"r_gwcode[590,Intercept]\"       \"r_gwcode[600,Intercept]\"       \"r_gwcode[615,Intercept]\"      \n## [103] \"r_gwcode[616,Intercept]\"       \"r_gwcode[620,Intercept]\"       \"r_gwcode[625,Intercept]\"      \n## [106] \"r_gwcode[626,Intercept]\"       \"r_gwcode[630,Intercept]\"       \"r_gwcode[640,Intercept]\"      \n## [109] \"r_gwcode[645,Intercept]\"       \"r_gwcode[651,Intercept]\"       \"r_gwcode[652,Intercept]\"      \n## [112] \"r_gwcode[660,Intercept]\"       \"r_gwcode[663,Intercept]\"       \"r_gwcode[666,Intercept]\"      \n## [115] \"r_gwcode[670,Intercept]\"       \"r_gwcode[678,Intercept]\"       \"r_gwcode[690,Intercept]\"      \n## [118] \"r_gwcode[692,Intercept]\"       \"r_gwcode[694,Intercept]\"       \"r_gwcode[696,Intercept]\"      \n## [121] \"r_gwcode[698,Intercept]\"       \"r_gwcode[700,Intercept]\"       \"r_gwcode[701,Intercept]\"      \n## [124] \"r_gwcode[702,Intercept]\"       \"r_gwcode[703,Intercept]\"       \"r_gwcode[704,Intercept]\"      \n## [127] \"r_gwcode[705,Intercept]\"       \"r_gwcode[710,Intercept]\"       \"r_gwcode[712,Intercept]\"      \n## [130] \"r_gwcode[731,Intercept]\"       \"r_gwcode[732,Intercept]\"       \"r_gwcode[750,Intercept]\"      \n## [133] \"r_gwcode[760,Intercept]\"       \"r_gwcode[770,Intercept]\"       \"r_gwcode[771,Intercept]\"      \n## [136] \"r_gwcode[775,Intercept]\"       \"r_gwcode[780,Intercept]\"       \"r_gwcode[790,Intercept]\"      \n## [139] \"r_gwcode[800,Intercept]\"       \"r_gwcode[811,Intercept]\"       \"r_gwcode[812,Intercept]\"      \n## [142] \"r_gwcode[816,Intercept]\"       \"r_gwcode[820,Intercept]\"       \"r_gwcode[830,Intercept]\"      \n## [145] \"r_gwcode[840,Intercept]\"       \"r_gwcode[850,Intercept]\"       \"r_gwcode[860,Intercept]\"      \n## [148] \"r_gwcode[910,Intercept]\"       \"r_gwcode[940,Intercept]\"       \"r_gwcode[950,Intercept]\"      \n## [151] \"r_gwcode[40,year_c]\"           \"r_gwcode[41,year_c]\"           \"r_gwcode[42,year_c]\"          \n## [154] \"r_gwcode[51,year_c]\"           \"r_gwcode[52,year_c]\"           \"r_gwcode[70,year_c]\"          \n## [157] \"r_gwcode[90,year_c]\"           \"r_gwcode[91,year_c]\"           \"r_gwcode[92,year_c]\"          \n## [160] \"r_gwcode[93,year_c]\"           \"r_gwcode[94,year_c]\"           \"r_gwcode[95,year_c]\"          \n## [163] \"r_gwcode[100,year_c]\"          \"r_gwcode[101,year_c]\"          \"r_gwcode[110,year_c]\"         \n## [166] \"r_gwcode[130,year_c]\"          \"r_gwcode[135,year_c]\"          \"r_gwcode[140,year_c]\"         \n## [169] \"r_gwcode[145,year_c]\"          \"r_gwcode[150,year_c]\"          \"r_gwcode[155,year_c]\"         \n## [172] \"r_gwcode[160,year_c]\"          \"r_gwcode[165,year_c]\"          \"r_gwcode[235,year_c]\"         \n## [175] \"r_gwcode[290,year_c]\"          \"r_gwcode[310,year_c]\"          \"r_gwcode[316,year_c]\"         \n## [178] \"r_gwcode[317,year_c]\"          \"r_gwcode[339,year_c]\"          \"r_gwcode[341,year_c]\"         \n## [181] \"r_gwcode[343,year_c]\"          \"r_gwcode[344,year_c]\"          \"r_gwcode[345,year_c]\"         \n## [184] \"r_gwcode[346,year_c]\"          \"r_gwcode[347,year_c]\"          \"r_gwcode[349,year_c]\"         \n## [187] \"r_gwcode[352,year_c]\"          \"r_gwcode[355,year_c]\"          \"r_gwcode[359,year_c]\"         \n## [190] \"r_gwcode[360,year_c]\"          \"r_gwcode[365,year_c]\"          \"r_gwcode[366,year_c]\"         \n## [193] \"r_gwcode[367,year_c]\"          \"r_gwcode[368,year_c]\"          \"r_gwcode[369,year_c]\"         \n## [196] \"r_gwcode[370,year_c]\"          \"r_gwcode[371,year_c]\"          \"r_gwcode[372,year_c]\"         \n## [199] \"r_gwcode[373,year_c]\"          \"r_gwcode[404,year_c]\"          \"r_gwcode[411,year_c]\"         \n## [202] \"r_gwcode[420,year_c]\"          \"r_gwcode[432,year_c]\"          \"r_gwcode[433,year_c]\"         \n## [205] \"r_gwcode[434,year_c]\"          \"r_gwcode[435,year_c]\"          \"r_gwcode[436,year_c]\"         \n## [208] \"r_gwcode[437,year_c]\"          \"r_gwcode[438,year_c]\"          \"r_gwcode[439,year_c]\"         \n## [211] \"r_gwcode[450,year_c]\"          \"r_gwcode[451,year_c]\"          \"r_gwcode[452,year_c]\"         \n## [214] \"r_gwcode[461,year_c]\"          \"r_gwcode[471,year_c]\"          \"r_gwcode[475,year_c]\"         \n## [217] \"r_gwcode[481,year_c]\"          \"r_gwcode[482,year_c]\"          \"r_gwcode[484,year_c]\"         \n## [220] \"r_gwcode[490,year_c]\"          \"r_gwcode[500,year_c]\"          \"r_gwcode[501,year_c]\"         \n## [223] \"r_gwcode[510,year_c]\"          \"r_gwcode[516,year_c]\"          \"r_gwcode[517,year_c]\"         \n## [226] \"r_gwcode[520,year_c]\"          \"r_gwcode[522,year_c]\"          \"r_gwcode[530,year_c]\"         \n## [229] \"r_gwcode[531,year_c]\"          \"r_gwcode[540,year_c]\"          \"r_gwcode[541,year_c]\"         \n## [232] \"r_gwcode[551,year_c]\"          \"r_gwcode[552,year_c]\"          \"r_gwcode[553,year_c]\"         \n## [235] \"r_gwcode[560,year_c]\"          \"r_gwcode[565,year_c]\"          \"r_gwcode[570,year_c]\"         \n## [238] \"r_gwcode[571,year_c]\"          \"r_gwcode[572,year_c]\"          \"r_gwcode[580,year_c]\"         \n## [241] \"r_gwcode[581,year_c]\"          \"r_gwcode[590,year_c]\"          \"r_gwcode[600,year_c]\"         \n## [244] \"r_gwcode[615,year_c]\"          \"r_gwcode[616,year_c]\"          \"r_gwcode[620,year_c]\"         \n## [247] \"r_gwcode[625,year_c]\"          \"r_gwcode[626,year_c]\"          \"r_gwcode[630,year_c]\"         \n## [250] \"r_gwcode[640,year_c]\"          \"r_gwcode[645,year_c]\"          \"r_gwcode[651,year_c]\"         \n## [253] \"r_gwcode[652,year_c]\"          \"r_gwcode[660,year_c]\"          \"r_gwcode[663,year_c]\"         \n## [256] \"r_gwcode[666,year_c]\"          \"r_gwcode[670,year_c]\"          \"r_gwcode[678,year_c]\"         \n## [259] \"r_gwcode[690,year_c]\"          \"r_gwcode[692,year_c]\"          \"r_gwcode[694,year_c]\"         \n## [262] \"r_gwcode[696,year_c]\"          \"r_gwcode[698,year_c]\"          \"r_gwcode[700,year_c]\"         \n## [265] \"r_gwcode[701,year_c]\"          \"r_gwcode[702,year_c]\"          \"r_gwcode[703,year_c]\"         \n## [268] \"r_gwcode[704,year_c]\"          \"r_gwcode[705,year_c]\"          \"r_gwcode[710,year_c]\"         \n## [271] \"r_gwcode[712,year_c]\"          \"r_gwcode[731,year_c]\"          \"r_gwcode[732,year_c]\"         \n## [274] \"r_gwcode[750,year_c]\"          \"r_gwcode[760,year_c]\"          \"r_gwcode[770,year_c]\"         \n## [277] \"r_gwcode[771,year_c]\"          \"r_gwcode[775,year_c]\"          \"r_gwcode[780,year_c]\"         \n## [280] \"r_gwcode[790,year_c]\"          \"r_gwcode[800,year_c]\"          \"r_gwcode[811,year_c]\"         \n## [283] \"r_gwcode[812,year_c]\"          \"r_gwcode[816,year_c]\"          \"r_gwcode[820,year_c]\"         \n## [286] \"r_gwcode[830,year_c]\"          \"r_gwcode[840,year_c]\"          \"r_gwcode[850,year_c]\"         \n## [289] \"r_gwcode[860,year_c]\"          \"r_gwcode[910,year_c]\"          \"r_gwcode[940,year_c]\"         \n## [292] \"r_gwcode[950,year_c]\"          \"lprior\"                        \"lp__\"                         \n## [295] \"accept_stat__\"                 \"treedepth__\"                   \"stepsize__\"                   \n## [298] \"divergent__\"                   \"n_leapfrog__\"                  \"energy__\"\n```\n:::\n\n\n- 142 country-specific intercept offsets: $b_{0_j}$\n- 142 country-specific offsets to the `year_c` slope: $b_{1_j}$\n- 2 global terms (intercept and `year_c`) for the $\\mu$ part of the model: $\\beta_0$ and $\\beta_1$\n- 2 global terms (intercept and `year_c`) for the hurdled $\\pi$ part of the model: $\\gamma_0$ and $\\gamma_1$\n- The overall within-country $\\sigma$: $\\sigma_y$\n- The variability in country-specific intercept and slope offsets: $\\sigma^2_0$ and $\\sigma^2_1$\n- The correlation between country-specific slopes and intercepts: $\\rho$\n- 8 auxiliary Stan-specific things like `lprior`, `n_leapfrog__`, `energy__`, etc.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nm_oda_prelim_time_only_total$model\n##  Family: hurdle_lognormal \n##   Links: mu = identity; sigma = identity; hu = logit \n## Formula: total_oda ~ year_c + (1 + year_c | gwcode) \n##          hu ~ year_c\n##    Data: dat (Number of observations: 3293) \n##   Draws: 4 chains, each with iter = 5000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 16000\n## \n## Group-Level Effects: \n## ~gwcode (Number of levels: 142) \n##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)             1.51      0.09     1.34     1.70 1.00     1345     3271\n## sd(year_c)                0.08      0.01     0.07     0.10 1.00     4844     8660\n## cor(Intercept,year_c)    -0.08      0.09    -0.26     0.10 1.00     3632     6793\n## \n## Population-Level Effects: \n##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept       19.74      0.13    19.49    20.00 1.00      673     1445\n## hu_Intercept    -3.09      0.10    -3.29    -2.91 1.00    24114    12594\n## hu_year_c        0.10      0.01     0.07     0.12 1.00    22946    13418\n## year_c           0.03      0.01     0.01     0.04 1.00     3278     6130\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     1.03      0.01     1.00     1.06 1.00    26366    11425\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nTo help with the intuition behind all these coefficients and moving parts in this hurdle model, though, it's helpful to walk through the different population-level (or global within-country) effects, group level (between-country) effects, and the within- and between-country variability. We also need to walk through these effects at each part of the model—the regular part that models $\\mu$ and the hurdled part that models $\\pi$.\n\n### Non-hurdled vs. hurdled parts (µ vs. π)\n\nBefore looking at population/global effects and group/country-level effects, we'll first explore the different parts of the model. We have three different parts to consider:\n\n$$\n\\begin{aligned}\n\\text{Foreign aid}_{it_j} &\\sim \\operatorname{Hurdle\\,log-normal}(\\pi_{it}, \\mu_{it_j}, \\sigma_y) & \\text{Overall aid} \\\\\n\\operatorname{logit}(\\pi_{it}) &= \\gamma_0 + \\gamma_1 \\text{Year}_{it} & \\text{0/not 0 process} \\\\\n\\log (\\mu_{it_j}) &= (\\beta_0 + b_{0_j}) + (\\beta_1 + b_{1_j}) \\text{Year}_{it_j} & \\text{$\\gt 0$ process}\n\\end{aligned}\n$$\n\nWe can explore the posterior distributions for each of these parts using different combinations of the `posterior_linpred()`, `posterior_epred()`, and `posterior_predict()` functions from {brms} (or their {tidybayes} counterparts `linpred_draws()`, `epred_draws()`, and `predicted_draws()`). I have [a whole detailed guide about the subtle differences between these](https://www.andrewheiss.com/blog/2022/09/26/guide-visualizing-types-posteriors/) (along with cheat sheets!) that I wrote in part because of this paper. See that guide for more details—here I'll be less verbose and pedagogical.\n\n#### Zero part (π and γs)\n\nFirst we can look at the hurdle part ($\\operatorname{logit}(\\pi_{it})$) that predicts if the outcome is 0 or not 0. In this example, we modeled this just with year, so we have a $\\gamma_0$ coefficient for the intercept and a $\\gamma_1$ coefficient for the year effect. These are on the logit scale, so exponentiating them will give us an odds ratio and inverse logit-ing them with `plogis()` will give us probabilities.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\n# Uninterpretable log odds\nm_oda_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\") %>% \n  filter(str_starts(term, \"hu_\"))\n## # A tibble: 2 × 7\n##   effect component term           estimate std.error conf.low conf.high\n##   <chr>  <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  cond      hu_(Intercept)  -3.09      0.0982  -3.29      -2.91 \n## 2 fixed  cond      hu_year_c        0.0951    0.0120   0.0720     0.119\n\n# Odds ratios\nm_oda_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\") %>% \n  filter(str_starts(term, \"hu_\")) %>% \n  mutate(across(c(estimate, conf.low, conf.high), exp))\n## # A tibble: 2 × 7\n##   effect component term           estimate std.error conf.low conf.high\n##   <chr>  <chr>     <chr>             <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  cond      hu_(Intercept)   0.0453    0.0982   0.0371    0.0547\n## 2 fixed  cond      hu_year_c        1.10      0.0120   1.07      1.13\n```\n:::\n\n\nThe intercept on both the logit and the odds scales is hard to interpret, but we can convert the log odds to the probability with $\\frac{e^{\\gamma_0}}{1 + e^{\\gamma_0}}$ or `plogis()`, which is 0.043, which means that in the year 2000 (i.e. when `year_c` is 0), the model predicts that 4.3% of countries received \\$0 in ODA.\n\nThe probability of receiving non-zero ODA increases by $e^{\\gamma_1}$ each year after that, or 1.1, or that a one-year increase in time makes it 10% more likely that a country will receive zero aid. \n\nOdds ratios are still weird to work with, so we can use probabilities instead. We can't just find the inverse logit of $\\gamma_1$ due to how logistic regression works—we have to incorporate information from the intercept too:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nhurdle_coefs <- m_oda_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\")\n\ngamma_0 <- hurdle_coefs %>% filter(term == \"hu_(Intercept)\") %>% pull(estimate)\ngamma_1 <- hurdle_coefs %>% filter(term == \"hu_year_c\") %>% pull(estimate)\n\navg_pp_year <- plogis(gamma_0 + gamma_1) - plogis(gamma_0)\navg_pp_year\n## b_hu_Intercept \n##        0.00412\n```\n:::\n\n\nThis implies that the proportion of zeros increases by 0.004 percentage points per year on average. Because this is a nonlinear model, the exact percentage point increase differs over time. We can instead look at predictions from the model using `linpred_draws(dpar = \"hu\", transform = TRUE)`. This will calculate predicted values from the $\\operatorname{logit}(\\pi_{it})$ part of the model. With `transform = FALSE`, it will return logit-scale values; with `transform = TRUE`, it will return probability-scale values.\n\nEven if we only account for year in the hurdle part of the model, we do a pretty good job predicting the proportion of zeros over time. In the actual data, there's an increase in zeros after 2005; in the model predictions we see the same thing (and note that in 2000 the predicted proportion is 4.3%, which is the same as the un-logit-ed intercept coefficient).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_hu_hu <- m_oda_prelim_time_only_total$model %>% \n  linpred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n                re_formula = NA,\n                dpar = \"hu\", transform = TRUE) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = hu)) +\n  stat_lineribbon(color = clrs$Emrld[7], alpha = 0.3) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = clrs$Emrld[2:4]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted proportion of\\ncountries receiving no aid\",\n       subtitle = \"Predicted global proportion of countries receiving no aid, π only\") +\n  theme_donors()\n\nplot_actual_zeros <- df_country_aid_laws %>% \n  group_by(year) %>% \n  summarize(prop_zero = sum(total_oda == 0) / n()) %>% \n  ggplot(aes(x = year, y = prop_zero)) + \n  geom_line(color = clrs$Emrld[5], linewidth = 1) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(x = NULL, y = \"Actual proportion of\\ncountries receiving no aid\",\n       subtitle = \"Actual global proportion of countries receiving no aid\") +\n  theme_donors()\n\n(plot_hu_hu / plot_actual_zeros) &\n  coord_cartesian(ylim = c(0, 0.2))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-prop-zeros-over-time-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n#### Non-zero part (µ ~~and βs~~)\n\nNext we can look at the non-hurdle part ($\\log (\\mu_{it_j})$) that predicts non-zero outcome values. We modeled this with year, so we have a $\\beta_0$ coefficient for the intercept and a $\\beta_1$ coefficient for the year slope, but we also have random country-specific offsets for both the intercept and slope. This will complicate life ([as explained below!](#global-analysis-βs-and-γs)) and means we can't really interpret these directly. But for now we'll pretend we can, just to understand how these coefficients work here.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\n# Logged values\nm_oda_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\") %>% \n  filter(!str_starts(term, \"hu_\"))\n## # A tibble: 2 × 7\n##   effect component term        estimate std.error conf.low conf.high\n##   <chr>  <chr>     <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  cond      (Intercept)  19.7      0.131    19.5      20.0   \n## 2 fixed  cond      year_c        0.0266   0.00776   0.0114    0.0417\n\n# Unlogged values\nm_oda_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\") %>% \n  filter(!str_starts(term, \"hu_\")) %>% \n  mutate(across(c(estimate, conf.low, conf.high), exp))\n## # A tibble: 2 × 7\n##   effect component term            estimate std.error     conf.low    conf.high\n##   <chr>  <chr>     <chr>              <dbl>     <dbl>        <dbl>        <dbl>\n## 1 fixed  cond      (Intercept) 374746463.     0.131   290176524.   482747838.  \n## 2 fixed  cond      year_c              1.03   0.00776         1.01         1.04\n```\n:::\n\n\n\n\nThe intercept here shows that the predicted average level of ODA in 2000 is $e^{19.7}$, or $374,746,463. The year effect on the log scale is hard to think about, but if we exponentiate it like $e^{0.027}$, we get 1.027, which is a multiplier effect like an odds ratio: ODA increases by 2.7% each year.\n\nWe can instead look at predictions from the model using `linpred_draws(transform = TRUE)`. This will calculate predicted values from the $\\log (\\mu_{it_j})$ part of the model. With `transform = FALSE`, it will return log-scale values; with `transform = TRUE`, it will return dollar-scale values. We could technically include `dpar = \"mu\"` to specify that we want values from the $\\mu$ part of the model, but that's also just the default, so there's no need. \n\nThe predicted value in 2000 is $374,746,463, like we found earlier. The line goes up, as expected. We *could* use {marginaleffects} to find the exact slope at a variety of locations along that line, but we'll skip that for now because doing that requires more nuance, given the multilevel nature of the model ([more on that below!](#global-analysis-βs-and-γs))\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_hu_mu_linpred <- m_oda_prelim_time_only_total$model %>% \n  linpred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n                re_formula = NA, dpar = \"mu\") %>% \n  mutate(.linpred = exp(.linpred)) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .linpred)) +\n  stat_lineribbon(color = clrs$PurpOr[7], alpha = 0.3) +\n  scale_y_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n  scale_fill_manual(values = clrs$PurpOr[3:5]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted foriegn aid\",\n       subtitle = \"Predicted global average foreign aid, µ only\") +\n  theme_donors()\nplot_hu_mu_linpred\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-linpred-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n#### Combined processes (*y*)\n\nFinally, we can look at both the hurdle ($\\operatorname{logit}(\\pi_{it})$) and non-hurdle ($\\log (\\mu_{it_j})$) parts of the model simultaneously. Recall from the formal model that the outcome is a function of both the $\\pi$ part and the $\\mu$ part:\n\n$$\n\\text{Foreign aid}_{it_j} \\sim \\operatorname{Hurdle\\,log-normal}(\\pi_{it}, \\mu_{it_j}, \\sigma_y)\n$$\n\nWe can work with both of these parts simultaneously if we use `epred_draws()` instead of `linpred_draws()`, which calculates the expectation (the \"e\" in epred) of the posterior predictive distribution of the outcome, or $\\textbf{E}(\\text{Foreign aid}_{it_j})$.\n\nThe plot of epred values is different from the linear predictor we found with the $\\mu$ part only—that's because we're now also incorporating the zero/non-zero process. In general the whole line is shift up higher—instead of ≈\\$400 million in 2000, we now see ≈\\$600ish million. The slope of the line is also a little wonky and dampened in later years—this is because the probability of zero aid is higher after 2005.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_hu_epred <- m_oda_prelim_time_only_total$model %>% \n  epred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n              re_formula = NA) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .epred)) +\n  stat_lineribbon(color = clrs$Peach[7], alpha = 0.3) +\n  scale_y_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n  scale_fill_manual(values = clrs$Peach[3:5]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted foriegn aid\",\n       subtitle = \"Predicted global average foreign aid, both µ and π\") +\n  theme_donors()\nplot_hu_epred\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-epred-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nHere's what all three of these plots look like simultaneously (just the $\\pi$ hurdling part, just the $\\mu$ non-hurdled part, and the combined epred part):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(plot_hu_hu / plot_hu_mu_linpred / plot_hu_epred) +\n  plot_annotation(title = \"Conditional effect of time on foreign aid\",\n                  subtitle = \"total_aid ~ year + (1 + year | country)\\nhu ~ year\",\n                  theme = theme(plot.title = element_text(family = \"Inter\", face = \"bold\"),\n                                plot.subtitle = element_text(family = \"Inconsolata\")))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-all-parts-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n### Global analysis (βs)\n\nWe looked at the coefficients for the non-hurdle-part intercept and slope up above, but that was a little wrong because of how multilevel models work. To show why (and to show how to actually interpret these things correctly), we'll look at the relationship between year and aid for the *typical* country, or just the global $\\beta_0$ and the global $\\beta_1$. Because we're using a generalized linear mixed model (GLMM), this is tricky! With normal Gaussian regression, we can interpret the $\\beta_0$ and $\\beta_1$ coefficients directly (and that's what [*Bayes Rules!*](https://www.bayesrulesbook.com/) [teaches here](https://bayesf22-notebook.classes.andrewheiss.com/bayes-rules/17-chapter.html#global-analysis-1), for instance). But GLMMs have link functions, which add a whole extra layer of complexity.\n\nWith GLMMs, we can talk about two different kinds of average global effects, or the confusingly named (1) conditional effects and (2) marginal effects. I have [a whole blog post guide about the distinction and how to calculate them](https://www.andrewheiss.com/blog/2022/11/29/conditional-marginal-marginaleffects/) (I actually wrote that post because of this project). The distinction between the two seems semantic but it's actually really quite important:\n\n- **Conditional effect = average country**: All $b_n$ offsets are set to 0 so that the effects or coefficients represent the effect in a typical country with the global average level of a variable.\n- **Marginal effect = countries on average**: All $b_n$ offsets are dealt with mathematically (averaged/marginalized out or integrated out) so that the effects or coefficients represent the effect of a variable across all countries on average.\n\nIn general, we're more interested in conditional effects, since @MuffHeldKeller:2016 argue that conditional models (i.e. average/typical country where offsets are set to 0) are the \"more powerful choice to explain how covariates are associated with a non-normal response\" rather than marginal models (i.e. countries on average). But we explore both here, because why not.\n\n#### Conditional effects\n\nSince the effect of year here is continuous, we can't just define the ATE as a contrast between when it is 1 vs. when it is 0. Instead, we want the instantaneous effect, or instantaneous slope/partial derivative of year. Rather than figure out the formal calculus for that, we'll use `marginaleffects()` to calculate the numerical derivative, which finds the predicted value of $Y$ at some value of $X$, finds the predicted value of $Y$ at some value of $X$ plus a tiny bit ($\\varepsilon$ here), subtracts them, and divides by $\\varepsilon$. For our situation here, it looks like this mess:\n\n$$\n\\frac{\\textbf{E}(\\text{ODA}_{i_j} \\mid \\{b_{0_j}, b_{0_j}\\} = 0, \\text{Year} = t + \\varepsilon) - \\textbf{E}(\\text{ODA}_{i_j} \\mid \\{b_{0_j}, b_{0_j}\\} = 0, \\text{Year} = t)}{\\varepsilon}\n$$\n\n{brms}'s syntax for $\\{b_{0_j}, b_{0_j}\\} = 0$ (i.e. setting all the random offsets to zero) is to use `re_formula = NA` in the different functions that generate predictions.\n\nTo see what this estimand looks like, it's helpful to first look at range of predicted values of ODA so we can see what line we're finding the slope for. To help with the intuition we'll look at the plots on both the link (log) scale and the back-transformed response (dollar) scale.\n\nWe can do this automatically with `marginaleffects::plot_cap()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\n# Log scale\nplot_cap(m_oda_prelim_time_only_total$model, \n         condition = \"year_c\", type = \"link\", \n         re_formula = NA)\n\n# Dollar scale\nplot_cap(m_oda_prelim_time_only_total$model, \n         condition = \"year_c\", type = \"response\", \n         re_formula = NA)\n```\n:::\n\n\nOr more manually with `epred_draws()`:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\npreds_log_hu <- m_oda_prelim_time_only_total$model %>% \n  linpred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n                re_formula = NA) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .linpred)) +\n  stat_lineribbon(color = clrs$Peach[7]) +\n  scale_y_continuous(labels = label_math(e^.x)) +\n  scale_fill_manual(values = clrs$Peach[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted log foriegn aid\") +\n  theme_donors()\n\npreds_dollar_hu <- m_oda_prelim_time_only_total$model %>% \n  epred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n              re_formula = NA) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .epred)) +\n  stat_lineribbon(color = clrs$Peach[7]) +\n  scale_y_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n  scale_fill_manual(values = clrs$Peach[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted foriegn aid\") +\n  theme_donors()\n\npreds_log_hu | preds_dollar_hu\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-conditional-predictions-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nThe slopes of both of these lines are actually fairly straight. On the log scale, the slope is constant and linear; on the dollar scale, the slope is generally pretty constant, though it starts to think about leveling out a tiny bit after 2005—that's because of the increased probability of seeing \\$0 in ODA starting in that year.\n\nWe can use `marginaleffects()` to get the exact slope of those lines at any value of `year_c` that we want, and we can plot those slopes across the whole range of years. On the log scale, the line is flat, since the slope is constant; on the dollar scale, it is mostly flat, with a slight drop in later years\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/calculate-conditional-mfx_fa37209b54342a698a3fac822c8576a2'}\n\n```{.r .cell-code}\nmfx_log_hu <- marginaleffects(\n  m_oda_prelim_time_only_total$model, \n  newdata = datagrid(year_c = seq(-10, 13, by = 1)),\n  variables = \"year_c\",\n  type = \"link\",\n  re_formula = NA\n)\n\nmfx_dollar_hu <- marginaleffects(\n  m_oda_prelim_time_only_total$model, \n  newdata = datagrid(year_c = seq(-10, 13, by = 1)),\n  variables = \"year_c\",\n  type = \"response\",\n  re_formula = NA\n)\n```\n:::\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_mfx_log_hu <- mfx_log_hu %>% \n  posteriordraws() %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = exp(draw))) +\n  stat_lineribbon(color = clrs$PurpOr[7]) +\n  scale_fill_manual(values = clrs$PurpOr[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Conditional effect (ratio)\") +\n  theme_donors()\n\nplot_mfx_dollar_hu <- mfx_dollar_hu %>% \n  posteriordraws() %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = draw)) +\n  stat_lineribbon(color = clrs$PurpOr[7]) +\n  scale_y_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n  scale_fill_manual(values = clrs$PurpOr[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Conditional effect (dollars)\") +\n  theme_donors()\n\nplot_mfx_log_hu | plot_mfx_dollar_hu\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-conditional-mfx-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nNote that the ratio-scale conditional effect is flat, while the dollar scale effect starts positive before making a downward turn in 2005. This is because {marginaleffects} uses epred values when you specify `type = \"response\"`, which means that the dollar-scale conditional effect incorporates the zero-process. When we specify `type = \"link\"`, we get log-scale effects, but those **don't** incorporate the zero process because {marginaleffects} uses linpred values. From the [marginaleffects brms vignette](https://vincentarelbundock.github.io/marginaleffects/articles/brms.html):\n\n> - `type = \"response\"`: Compute posterior draws of the expected value using the `brms::posterior_epred` function.\n> - `type = \"link\"`: Compute posterior draws of the linear predictor using the `brms::posterior_linpred` function.\n> - `type = \"prediction\"`: Compute posterior draws of the posterior predictive distribution using the `brms::posterior_predict` function.\n\nTo help even more with the intuition, here are the exact slopes (or conditional effects) at 1990, 2000, and 2010, both on the log scale and the dollar scale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_log_hu_small <- mfx_log_hu %>% \n  filter(year_c %in% c(-10, 0, 10)) %>% \n  mutate(year = 2000 + year_c) %>% \n  select(year, dydx, conf.low, conf.high) %>% \n  mutate(across(c(dydx, conf.low, conf.high), list(exp = ~exp(.))))\n\nmfx_dollar_hu_small <- mfx_dollar_hu %>% \n  filter(year_c %in% c(-10, 0, 10)) %>% \n  mutate(year = 2000 + year_c) %>% \n  select(year, dydx, conf.low, conf.high) %>% \n  mutate(across(c(dydx, conf.low, conf.high), ~label_dollar()(.)))\n\nmfx_log_hu_small\n##   year   dydx conf.low conf.high dydx_exp conf.low_exp conf.high_exp\n## 1 1990 0.0266   0.0114    0.0422     1.03         1.01          1.04\n## 2 2000 0.0266   0.0114    0.0422     1.03         1.01          1.04\n## 3 2010 0.0266   0.0114    0.0422     1.03         1.01          1.04\nmfx_dollar_hu_small\n##   year        dydx   conf.low   conf.high\n## 1 1990 $11,805,637 $5,299,453 $17,798,017\n## 2 2000 $13,568,153 $4,306,228 $24,032,849\n## 3 2010 $12,211,093   $301,785 $28,833,142\n```\n:::\n\n\n\n\nInterpretation time. We can look at these effects a few different ways. On the log scale, a one-year increase in time is associated with a 0.027 increase in logged ODA **in a typical country**. Logged values alone don't make sense, but if we exponentiate them, we can talk about percent changes (or multiplier effects) in the outcome. Here, $e^{0.027}$ is 1.027, which means that ODA increases by 3% each year **in a typical country**, with a 95% credible interval of 1.1% to 4.3%. This is the same in every year. We can also look at the dollar scale, which is different across time. In 1990, the conditional effect of a one-year increase in time is $11,805,637, while in 2000 it is $13,568,153.\n\nSince we have posteriors, we might as well use them and visualize the distributions of these effects:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- mfx_log_hu %>% \n  posteriordraws() %>% \n  filter(year_c == 0) %>% \n  ggplot(aes(x = draw)) +\n  stat_halfeye(fill = clrs$PurpOr[5]) +\n  labs(x = \"Conditional effect of\\nyear on ODA, log scale\", y = NULL,\n       subtitle = \"Log scale\", fill = NULL) +\n  theme_donors()\n\np2 <- mfx_log_hu %>% \n  posteriordraws() %>% \n  filter(year_c == 0) %>% \n  ggplot(aes(x = exp(draw))) +\n  stat_halfeye(fill = clrs$PurpOr[7]) +\n  labs(x = \"Conditional effect of\\nyear on ODA, exponentiated\", y = NULL,\n       subtitle = \"Exponentiated scale\", fill = NULL) +\n  theme_donors()\n\np3 <- mfx_dollar_hu %>% \n  posteriordraws() %>% \n  filter(year_c %in% c(-10, 0, 10)) %>% \n  mutate(year = year_c + 2000) %>% \n  pivot_longer(draw) %>% \n  ggplot(aes(x = value, fill = factor(year))) +\n  stat_halfeye(alpha = 0.7) +\n  scale_x_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n  scale_fill_manual(values = clrs$Sunset[c(2, 4, 6)]) +\n  labs(x = \"Conditional effect of\\nyear on ODA, dollars\", y = NULL,\n       subtitle = \"Dollar scale\", fill = NULL) +\n  theme_donors()\n\n(p1 | p2 | p3) + \n  plot_annotation(title = \"Conditional effect of year on ODA for a typical country\",\n                  theme = theme(plot.title = element_text(family = \"Inter\", face = \"bold\")))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-hu-conditional-mfx-all-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nAgain, these are all conditional effects, which means that they represent the effect of year **for a typical country**, or a country where all the country-specific offsets are 0.\n\n#### Marginal effects\n\nInstead of looking at the effect of year **in an average country** (or the *conditional effect*) by setting $\\{b_{0_j}, b_{0_j}\\} = 0$, we can look at the effect of year **in all countries on average** (or the *marginal effect*) by mathematically incorporating information about all countries' random offsets. Because we're working with a continuous treatment, our estimand is an instantaneous slope, which we calculate with the same numerical derivative approach we used earlier for the conditional effects (i.e. the difference between the effect when year is set to something and when year is set to something + a tiny amount ($\\varepsilon$), divided by $\\varepsilon$):\n\n$$\n\\frac{\\textbf{E}(\\text{ODA}_{i_j} \\mid \\text{Year} = t + \\varepsilon) - \\textbf{E}(\\text{ODA}_{i_j} \\mid \\text{Year} = t)}{\\varepsilon}\n$$\n\nThe nomenclature here is absolutely maddening. \n\nWe just used the `marginaleffects()` function to find the instantaneous slopes for our conditional effects up above, but that kind of slope-based marginal effect is unrelated to the all-countries-on-average-marginal-effect-that-is-not-a-conditional-average-country-effect effect. We use `marginaleffects()` to find both. The only difference is that for *conditional* marginal effects, we set `re_formula = NA` to make the country offsets zero; for *marginal* marginal effects, we'll set `re_formula = NULL` to include the country offsets, and we do some simulation-based trickery to average over or integrate out those offsets.\n\n##### Average / marginalize / integrate across existing random effects\n\nThe first way to deal with the country-specific offsets is to average (or marginalize or integrate across—all of these mean the same thing) all the existing random effects. In practice this means calculating the instantaneous slope of `year_c` in each of the countries, then collapsing those estimates into one average. `marginaleffects()` makes this easy\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_log_marginal_hu <- marginaleffects(\n  m_oda_prelim_time_only_total$model, \n  newdata = datagrid(gwcode = unique),\n  variables = \"year_c\",\n  type = \"link\",\n  re_formula = NULL\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_log_marginal_hu %>% tidy()\n##   type   term estimate conf.low conf.high\n## 1 link year_c   0.0267   0.0205     0.033\n```\n:::\n\n\n##### Integrate out random effects\n\nThe second way to deal with the random effects is to invent a bunch of hypothetical countries that all have different simulated country-specific offsets based on the distributions of $\\sigma_0$ and $\\sigma_1$, and then calculate the instantaneous slope in each of those fake countries, *and then* collapse those country-specific slopes into one average. This is the equivalent of *integrating out* the random effects. Here we'll invent 200 fake countries:\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/calculate-marginal-hu-integrated-out_5f974b30e29e8336c7641dd0630c8634'}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_log_marginal_hu_int <- marginaleffects(\n  m_oda_prelim_time_only_total$model, \n  variables = \"year_c\",\n  newdata = datagrid(gwcode = c(-1:-200)),\n  re_formula = NULL,\n  allow_new_levels = TRUE,\n  sample_new_levels = \"gaussian\",\n  type = \"link\"\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_log_marginal_hu_int %>% tidy()\n##   type   term estimate conf.low conf.high\n## 1 link year_c   0.0266  0.00693    0.0464\n```\n:::\n\n\n##### Comparing the two\n\nIn this case, since we have so many countries (142 real ones vs. 200 fake ones), the estimates are basically the same. If we were working with fewer real countries, the estimates from the average / marginalize / integrate across approach would be less accurate.\n\nWhile the posterior means are the same, the integrating out approach has a lot more uncertainty associated with it:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_marginal_hu <- mfx_log_marginal_hu %>% \n  posteriordraws() %>% \n  group_by(type, term, drawid) %>% \n  summarize(draw = mean(draw))\n\ndata_int_hu <- mfx_log_marginal_hu_int %>% \n  posteriordraws() %>% \n  group_by(type, term, drawid) %>% \n  summarize(draw = mean(draw))\n\nplot_marginal_mfx_both <- ggplot(mapping = aes(x = exp(draw))) +\n  stat_halfeye(data = data_int_hu, aes(fill = \"Integrated out\")) +\n  stat_halfeye(data = data_marginal_hu, aes(fill = \"Averaged across\"), \n               slab_color = \"white\", slab_linewidth = 0.5) +\n  scale_fill_manual(values = clrs$Peach[c(2, 5)]) +\n  coord_cartesian(xlim = c(1, 1.06)) +\n  labs(x = \"Marginal effect of\\nyear on ODA, exponentiated\", y = NULL,\n       fill = \"Random effect marginalizing method\",\n       title = \"Marginal marginal effects\",\n       subtitle = \"Effect of year on ODA across all countries on average\") +\n  theme_donors()\nplot_marginal_mfx_both\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-marginal-mfx-both-hu-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n### Country-specific analysis (*b* offsets and ρ)\n\nThere are 142 different countries, each with their own intercept offsets and slope offsets, so I won't plot them here (but [check out this example](https://bayesf22-notebook.classes.andrewheiss.com/bayes-rules/17-chapter.html#runner-specific-analysis) to see what a plot like that could look like). We can look at the first few of these different country-specific offsets to help with the intuition. Each country's random effects are $b_0$ and $b_1$. These offsets get added to the global averages $\\beta_0$ and $\\beta_1$, giving each country its own unique slope and intercept.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nm_oda_prelim_time_only_total$model %>%  \n  spread_draws(b_Intercept, b_year_c, r_gwcode[gwcode, term]) %>%  \n  pivot_wider(names_from = \"term\", values_from = r_gwcode) %>%  \n  mutate(country_intercept = b_Intercept + Intercept,\n         country_year_slope = b_year_c + year_c) %>%  \n  group_by(gwcode) %>%  \n  summarize(across(c(b_Intercept, Intercept, country_intercept, \n                     b_year_c, year_c, country_year_slope), \n                   ~median(.))) %>% \n  rename(`β0` = b_Intercept, `b0 offset` = Intercept, \n         `Intercept` = country_intercept,\n         `β1` = b_year_c, `b1 offset` = year_c,\n         `Year slope` = country_year_slope)\n## # A tibble: 142 × 7\n##    gwcode    β0 `b0 offset` Intercept     β1  `b1 offset` `Year slope`\n##     <int> <dbl>       <dbl>     <dbl>  <dbl>        <dbl>        <dbl>\n##  1     40  19.7     -2.20        17.5 0.0266  0.134            0.160  \n##  2     41  19.7      0.286       20.0 0.0266  0.0635           0.0900 \n##  3     42  19.7      0.243       20.0 0.0266  0.0101           0.0367 \n##  4     51  19.7      0.0222      19.8 0.0266 -0.0661          -0.0397 \n##  5     52  19.7     -1.06        18.7 0.0266 -0.111           -0.0841 \n##  6     70  19.7      2.67        22.4 0.0266 -0.0212           0.00559\n##  7     90  19.7      0.561       20.3 0.0266  0.000000950      0.0268 \n##  8     91  19.7      0.599       20.3 0.0266 -0.0180           0.00844\n##  9     92  19.7      0.517       20.3 0.0266 -0.0397          -0.0129 \n## 10     93  19.7      0.926       20.7 0.0266 -0.0454          -0.0189 \n## # … with 132 more rows\n```\n:::\n\n\nWe can make a spaghetti plot of these country-specific offsets, both at the log scale and the dollar scale:\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/calculate-country-lines-hu_0c011317db77e63827ce3753224995cb'}\n\n```{.r .cell-code}\nall_country_lines_hu <- m_oda_prelim_time_only_total$model %>%  \n  epred_draws(expand_grid(gwcode = unique(df_country_aid_laws$gwcode),\n                            year_c = seq(-10, 13, by = 1))) %>%  \n  group_by(gwcode, year_c) %>%  \n  median_qi(.epred) %>%  \n  mutate(year = year_c + 2000)\n```\n:::\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- all_country_lines_hu %>% \n  ggplot(aes(x = year, y = .epred)) +\n  geom_line(aes(group = gwcode),\n            color = clrs$Prism[1], linewidth = 0.15) +\n  scale_y_continuous(trans = log_trans(),\n                     labels = label_math(e^.x, format = log)) +\n  labs(x = NULL, y = \"ODA (logged)\") +\n  theme_donors()\n\np2 <- all_country_lines_hu %>% \n  ggplot(aes(x = year, y = .epred)) +\n  geom_line(aes(group = gwcode),\n            color = clrs$Prism[1], linewidth = 0.15) +\n  scale_y_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +\n  labs(x = NULL, y = \"ODA (dollars)\") +\n  coord_cartesian(ylim = c(0, 10e9)) +\n  theme_donors()\n\np1 | p2\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-country-lines-hu-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nDue to the magic of multilevel models, these intercept and slope offsets are actually correlated with each other—we modeled the offsets from a multivariate normal distribution, and the correlation between the two $b_{n_j}$ parameters is defined by $\\rho_{0, 1}$:\n\n$$\n\\left(\n  \\begin{array}{c} \n  b_{0_j} \\\\\n  b_{1_j}\n  \\end{array}\n\\right) \n\\sim \\text{MV}\\,\\mathcal{N}\n\\left[\n  \\left(\n    \\begin{array}{c}\n    0 \\\\\n    0 \\\\\n    \\end{array}\n  \\right)\n  , \\,\n  \\left(\n  \\begin{array}{cc}\n     \\sigma^2_{0} & {\\color{red} \\rho_{0, 1}}\\, \\sigma_{0} \\sigma_{1} \\\\ \n     \\cdots & \\sigma^2_{1}\n  \\end{array}\n\\right)\n\\right]\n$$\n\n[Section 17.3](https://www.bayesrulesbook.com/chapter-17.html#model-building-1) in *Bayes Rules!* illustrates what this correlation means in practice, and I made [my own version of their plot here](https://bayesf22-notebook.classes.andrewheiss.com/bayes-rules/17-chapter.html#hierarchical-model-with-varying-intercepts-slopes):\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/rho-plot.png){fig-align='center' width=100%}\n:::\n:::\n\n\nWhen $\\rho$ is negative, bigger intercepts have smaller slopes; when $\\rho$ is positive, bigger intercepts have bigger slopes. With our data, if $\\rho$ is big and positive it would imply that countries with higher baseline levels of aid would see a larger and steeper year effect. In our actual model, $\\rho$ is basically zero though:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_oda_prelim_time_only_total$model %>% \n  spread_draws(cor_gwcode__Intercept__year_c) %>% \n  ggplot(aes(x = cor_gwcode__Intercept__year_c)) +\n  stat_halfeye(fill = clrs$Prism[2]) +\n  geom_vline(xintercept = 0) +\n  labs(x = \"ρ<sub>0, 1</sub>\", y = NULL) +\n  theme_donors() +\n  theme(axis.title.x = element_markdown())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/rho-dist-hu-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nDoes this $\\rho$ term have any practical application for the question we're answering here? Not really. Is it super neat anyway? Yep.\n\n\n### Within- and between-country variability (σs)\n\n\n\n\n\nFinally, we can look at all the $\\sigma$ terms. We have three to work with:\n\n- $\\sigma_y$ (`sd__Observation`): the variability of aid within countries. It's 1.03, which means that within any country, their total ODA varies by 1 logged unit, so if their baseline is $e^{19}$, their outcome will bounce around between $e^{18}$ and $e^{20}$ over time.\n- $\\sigma_0$ (`sd__(Intercept)` for the `gwcode` group): the variability between countries' baseline averages, or the variability around the $b_{0_j}$ offsets. Here it's 1.51, which means that across or between countries, total ODA varies by 1.5 logged units.\n- $\\sigma_1$ (`sd__year_c` for the `gwcode` group): the variability between countries' year effects, or the variability around the $b_{1_j}$ offsets. Here it's 0.08, which means that average year effects vary by 8ish% across or between countries.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nm_oda_prelim_time_only_total$model %>% \n  tidy(effects = \"ran_pars\") %>% \n  select(-component, -effect) %>% \n  filter(!str_starts(term, \"cor\"))\n## # A tibble: 3 × 6\n##   group    term            estimate std.error conf.low conf.high\n##   <chr>    <chr>              <dbl>     <dbl>    <dbl>     <dbl>\n## 1 gwcode   sd__(Intercept)   1.51     0.0937    1.34      1.70  \n## 2 gwcode   sd__year_c        0.0847   0.00632   0.0732    0.0979\n## 3 Residual sd__Observation   1.03     0.0138    1.00      1.06\n```\n:::\n\n\nFor whatever reason, we can’t get an ICC for the percent of variation explained by between-country differences:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nperformance::icc(m_oda_prelim_time_only_total$model)\n## [1] NA\n```\n:::\n\n\nWe *can* use `performance::variance_decomposition()` to get a comparable number, since it uses the posterior predictive distribution of the model to figure out the between-country variance. It looks like between-country differences explain like 97% of the variation in ODA? Maybe that's true, or maybe that's an artifact of the WEIRDLY MASSIVE variance values it calculated here (the difference in variances is in the quintillions!). idk.\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/model-prelim-icc_aab6d4a5dbe739b3ee517b8ec40caf83'}\n\n```{.r .cell-code  code-fold=\"show\"}\nperformance::variance_decomposition(m_oda_prelim_time_only_total$model)\n## # Random Effect Variances and ICC\n## \n## Conditioned on: all random effects\n## \n## ## Variance Ratio (comparable to ICC)\n## Ratio: 0.97  CI 95%: [0.93 0.99]\n## \n## ## Variances of Posterior Predicted Distribution\n## Conditioned on fixed effects:   852776255087778048.00  CI 95%: [  472418355353042944.00  1633097449873477376.00]\n## Conditioned on rand. effects: 28350410596168671232.00  CI 95%: [16026107771162734592.00 89196474994505465856.00]\n## \n## ## Difference in Variances\n## Difference: 27452860054043279360.00  CI 95%: [15096287018349314048.00 88040877640079458304.00]\n```\n:::\n\n\n\n# Zero-inflated models (proportions)\n\nOur different proportion variables also have a substantial number of zeros:\n\n::: {.panel-tabset}\n## Proportion of contentious aid\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_country_aid_laws %>% \n  mutate(prop_contentious = ifelse(prop_contentious == 0, -0.05, prop_contentious)) %>% \n  ggplot(aes(x = year, y = prop_contentious)) +\n  geom_line(aes(group = country), linewidth = 0.075, alpha = 0.5) +\n  stat_summary(geom = \"line\", fun = \"mean\", color = clrs$Prism[8], linewidth = 1.25) +\n  geom_hline(yintercept = 0.001) +\n  scale_y_continuous(labels = c(\"Exactly 0%\", \">0%\", \"25%\", \"50%\", \"75%\", \"100%\"), \n                     breaks = c(-0.05, 0.001, 0.25, 0.5, 0.75, 1)) +\n  labs(x = NULL, y = \"Proportion of contentious aid\", color = NULL) +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-all-prop-contentious-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Proportion of aid to domestic NGOs\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_country_aid_laws %>% \n  filter(year >= 2000) %>% \n  mutate(prop_ngo_dom = ifelse(prop_ngo_dom == 0, -0.05, prop_ngo_dom)) %>% \n  ggplot(aes(x = year, y = prop_ngo_dom)) +\n  geom_line(aes(group = country), linewidth = 0.075, alpha = 0.5) +\n  stat_summary(geom = \"line\", fun = \"mean\", color = clrs$Prism[8], linewidth = 1.25) +\n  geom_hline(yintercept = 0.001) +\n  scale_y_continuous(labels = c(\"Exactly 0%\", \">0%\", \"25%\", \"50%\", \"75%\", \"100%\"), \n                     breaks = c(-0.05, 0.001, 0.25, 0.5, 0.75, 1)) +\n  labs(x = NULL, y = \"Proportion of aid to domestic NGOs\", color = NULL) +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-all-prop-ngo-domestic-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Proportion of aid to foreign NGOs\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_country_aid_laws %>% \n  filter(year >= 2000) %>% \n  mutate(prop_ngo_foreign = ifelse(prop_ngo_foreign == 0, -0.05, prop_ngo_foreign)) %>% \n  ggplot(aes(x = year, y = prop_ngo_foreign)) +\n  geom_line(aes(group = country), linewidth = 0.075, alpha = 0.5) +\n  stat_summary(geom = \"line\", fun = \"mean\", color = clrs$Prism[8], linewidth = 1.25) +\n  geom_hline(yintercept = 0.001) +\n  scale_y_continuous(labels = c(\"Exactly 0%\", \">0%\", \"25%\", \"50%\", \"75%\", \"100%\"), \n                     breaks = c(-0.05, 0.001, 0.25, 0.5, 0.75, 1)) +\n  labs(x = NULL, y = \"Proportion of aid to foreign NGOs\", color = NULL) +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-all-prop-ngo-foreign-1.png){fig-align='center' width=80%}\n:::\n:::\n\n:::\n\nAs with total aid, we're not entirely sure what the underlying zero inflation process looks like for the different proportion variables we care about. For the proportion of contentious aid there's a definite parabolic time trend, similar to what we saw with the hurdled model of ODA. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_country_aid_laws %>% \n  group_by(year) %>% \n  summarize(prop_zero = mean(prop_contentious == 0)) %>% \n  ggplot(aes(x = year, y = prop_zero)) +\n  geom_line(linewidth = 0.5, color = \"grey70\") +\n  geom_point(size = 1) + \n  geom_smooth(aes(color = \"y = x\"), method = \"lm\", \n              formula = y ~ x, se = FALSE) +\n  geom_smooth(aes(color = \"y = x + x<sup>2</sup>\"), method = \"lm\", \n              formula = y ~ x + I(x^2), se = FALSE) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_color_manual(values = clrs$Prism[c(3, 11)]) +\n  labs(x = NULL, y = \"Proportion of countries\\nwith zero contentious aid\",\n       color = NULL) +\n  theme_donors() +\n  theme(legend.text = element_markdown())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-prop-zero-zi-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Formal statistical model\n\nTo account for this underlying zero-inflation process, we'll use a [zero-inflated beta family](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/) with a multilevel hierarchical model with country-specific intercepts and a year trend with country-specific offsets (again [following best practices for working with panel data with multilevel models](https://www.andrewheiss.com/blog/2021/12/01/multilevel-models-panel-data-guide/)). Earlier we didn't include any polynomials to make it easier to interpret things. Here, for the sake of practice and illustration, we *will* add a squared term for year. As before, we center the year at 2000, and we'll just look at the effect of year on contentious aid, since this is just a general illustration of how to work with these models.\n\nIn {brms}'s [random effects syntax](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification), the model formula looks like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nbf(prop_contentious ~ year_c + (1 + year_c | gwcode),\n   zi ~ year_c + I(year_c^2))\n```\n:::\n\n\n@eq-zibeta-baseline shows this in more formal mathematical notation, with all the different random effects offsets and priors all working together simultaneously:\n\n::: {.column-page-inset-right}\n\n$$\n\\begin{aligned}\n& \\mathrlap{\\textbf{Zero-inflated model of proportion $i$ across time $t$ within each country $j$}} \\\\\n\\text{Proportion}_{it_j} &\\sim \\operatorname{Zero-inflated\\, Beta}(\\pi_{it}, \\mu_{it_j}, \\phi_y) \\\\\n\\\\\n& \\textbf{Models for distribution parameters} \\\\\n\\operatorname{logit}(\\pi_{it}) &= \\gamma_0 + \\gamma_1 \\text{Year}_{it} + \\gamma_2 \\text{Year}^2_{it} & \\text{Zero/not-zero process} \\\\[4pt]\n\\operatorname{logit}(\\mu_{it_j}) &= (\\beta_0 + b_{0_j}) + (\\beta_1 + b_{1_j}) \\text{Year}_{it_j} & \\text{Within-country variation} \\\\[4pt]\n\\left(\n  \\begin{array}{c} \n  b_{0_j} \\\\\n  b_{1_j}\n  \\end{array}\n\\right) \n&\\sim \\text{MV}\\,\\mathcal{N}\n\\left[\n  \\left(\n    \\begin{array}{c}\n    0 \\\\\n    0 \\\\\n    \\end{array}\n  \\right)\n  , \\,\n  \\left(\n  \\begin{array}{cc}\n     \\sigma^2_{0} & \\rho_{0, 1}\\, \\sigma_{0} \\sigma_{1} \\\\ \n     \\cdots & \\sigma^2_{1}\n  \\end{array}\n\\right)\n\\right] & \\text{Variability in average intercepts and slopes} \\\\\n\\\\\n& \\textbf{Priors} \\\\\n\\gamma_0 &\\sim \\text{Student $t$}(3, 0, 1.5) & \\text{Prior for intercept in hurdle model} \\\\\n\\gamma_1, \\gamma_2 &\\sim \\text{Student $t$}(3, 0, 1.5) & \\text{Prior for year effect in hurdle model} \\\\\n\\beta_0 &\\sim \\text{Student $t$}(3, 0, 1.5) & \\text{Prior for global average proportion} \\\\\n\\beta_1 &\\sim \\text{Student $t$}(3, 0, 1.5) & \\text{Prior for global year effect} \\\\\n\\phi_y &\\sim \\operatorname{Exponential}(1) & \\text{Prior for within-country variability} \\\\\n\\sigma_0 &\\sim \\operatorname{Exponential}(1) & \\text{Prior for between-country intercept variability} \\\\\n\\sigma_1 &\\sim \\operatorname{Exponential}(1) & \\text{Prior for between-country slope variability} \\\\\n\\rho &\\sim \\operatorname{LKJ}(2) & \\text{Prior for between-country variability}\n\\end{aligned}\n$$ {#eq-zibeta-baseline}\n\n:::\n\n## Prior simulation\n\nFor this year-and-country-only model, we set the following priors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndesign <- \"\n  AAABBB\n  CCCDDD\n  EEFFGG\n\"\n\nm_purpose_prelim_time_only_total$priors %>% \n  parse_dist() %>% \n  # K = dimension of correlation matrix; \n  # ours is 2x2 here because we have one random slope\n  marginalize_lkjcorr(K = 2) %>%\n  mutate(nice_title = glue::glue(\"**{class}**: {prior}\"),\n         stage = ifelse(dpar == \"zi\", \"Zero-inflated part (π)\", \"Beta part (µ and φ)\")) %>% \n  mutate(nice_title = fct_inorder(nice_title),\n         stage = fct_rev(fct_inorder(stage))) %>% \n  ggplot(aes(y = 0, dist = .dist, args = .args, fill = prior)) +\n  stat_slab(normalize = \"panels\") +\n  scale_fill_manual(values = clrs$Prism[c(1, 2, 5)]) +\n  facet_manual(vars(stage, nice_title), design = design, scales = \"free_x\",\n               strip = strip_nested(background_x = list(element_rect(fill = \"grey92\"), NULL),\n                                    by_layer_x = TRUE)) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = NULL) +\n  theme_donors(prior = TRUE) +\n  theme(strip.text = element_markdown())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-priors-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nAs we did with the hurdle model, we'll simulate from the prior distributions to make sure these are reasonable-ish. These are kind of neat. Some simulated countries have a good range of contentious aid over time; others jump between 0% and 100% pretty rapidly (which also happens in the real data). These priors are fine enough.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_country_aid_laws %>%  \n  add_epred_draws(m_purpose_prelim_time_only_total$model_prior_only, ndraws = 9,\n                  seed = 12345) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .epred, group = paste(gwcode, .draw))) +\n  geom_line(linewidth = 0.15, color = clrs$Prism[8]) +\n  scale_y_continuous(labels = label_percent()) +\n  facet_wrap(vars(.draw)) +\n  labs(x = \"Year\", y = \"Percent of contentious aid\", title = \"Results sampled from prior only\",\n       subtitle = \"Each panel shows plausible aid-year relationships for 142 simulated countries\") +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/prior-simulations-zi-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n## Posterior checks\n\n### MCMC diagnostics\n\n::: {.panel-tabset}\n\n#### Trace plots\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_purpose_prelim_time_only_total$model %>% \n  gather_draws(`^b_.*|^sd_.*|^cor_.*|^phi`, regex = TRUE) %>% \n  ggplot(aes(x = .iteration, y = .value, color = factor(.chain))) +\n  geom_line(size = 0.1) +\n  scale_color_manual(values = clrs$Sunset[3:6]) +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-trace-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n#### Trank plots\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_purpose_prelim_time_only_total$model %>% \n  gather_draws(`^b_.*|^sd_.*|^cor_.*|^phi`, regex = TRUE) %>% \n  group_by(.variable) %>% \n  mutate(draw_rank = rank(.value)) %>% \n  ggplot(aes(x = draw_rank, color = factor(.chain))) +\n  stat_bin(geom = \"step\", binwidth = 500, position = position_identity(), boundary = 0) +\n  scale_color_manual(values = clrs$Sunset[3:6]) +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme_donors() +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-trank-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n#### MCMC duration\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nrstan::get_elapsed_time(m_purpose_prelim_time_only_total$model$fit)\n##         warmup sample\n## chain:1   94.8  100.3\n## chain:2   97.6   53.6\n## chain:3   99.8   58.3\n## chain:4   96.5   53.6\n\nrstan::get_elapsed_time(m_purpose_prelim_time_only_total$model$fit) %>% \n  as.data.frame() %>% \n  summarize(longest = lubridate::as.duration(max(warmup + sample)))\n##                    longest\n## 1 195.157s (~3.25 minutes)\n```\n:::\n\n\n:::\n\n### Posterior predictive check\n\nIt's so beautiful!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwithr::with_seed(1234, {\n  pp_check(m_purpose_prelim_time_only_total$model, ndraws = 20) +\n    labs(x = \"Percent of contentious aid\", \n         title = \"Zero-inflated beta model posterior predictive check\") +\n    scale_x_continuous(labels = label_percent()) +\n    theme_donors()\n})\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-pp-check-zi-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Analyzing the posterior\n\nThough we only really care about one effect here, we actually have a ton of different parameters to work with—301!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the full list of 301 things\"}\nget_variables(m_purpose_prelim_time_only_total$model)\n##   [1] \"b_Intercept\"                   \"b_zi_Intercept\"                \"b_zi_year_c\"                  \n##   [4] \"b_zi_Iyear_cE2\"                \"b_year_c\"                      \"sd_gwcode__Intercept\"         \n##   [7] \"sd_gwcode__year_c\"             \"cor_gwcode__Intercept__year_c\" \"phi\"                          \n##  [10] \"r_gwcode[40,Intercept]\"        \"r_gwcode[41,Intercept]\"        \"r_gwcode[42,Intercept]\"       \n##  [13] \"r_gwcode[51,Intercept]\"        \"r_gwcode[52,Intercept]\"        \"r_gwcode[70,Intercept]\"       \n##  [16] \"r_gwcode[90,Intercept]\"        \"r_gwcode[91,Intercept]\"        \"r_gwcode[92,Intercept]\"       \n##  [19] \"r_gwcode[93,Intercept]\"        \"r_gwcode[94,Intercept]\"        \"r_gwcode[95,Intercept]\"       \n##  [22] \"r_gwcode[100,Intercept]\"       \"r_gwcode[101,Intercept]\"       \"r_gwcode[110,Intercept]\"      \n##  [25] \"r_gwcode[130,Intercept]\"       \"r_gwcode[135,Intercept]\"       \"r_gwcode[140,Intercept]\"      \n##  [28] \"r_gwcode[145,Intercept]\"       \"r_gwcode[150,Intercept]\"       \"r_gwcode[155,Intercept]\"      \n##  [31] \"r_gwcode[160,Intercept]\"       \"r_gwcode[165,Intercept]\"       \"r_gwcode[235,Intercept]\"      \n##  [34] \"r_gwcode[290,Intercept]\"       \"r_gwcode[310,Intercept]\"       \"r_gwcode[316,Intercept]\"      \n##  [37] \"r_gwcode[317,Intercept]\"       \"r_gwcode[339,Intercept]\"       \"r_gwcode[341,Intercept]\"      \n##  [40] \"r_gwcode[343,Intercept]\"       \"r_gwcode[344,Intercept]\"       \"r_gwcode[345,Intercept]\"      \n##  [43] \"r_gwcode[346,Intercept]\"       \"r_gwcode[347,Intercept]\"       \"r_gwcode[349,Intercept]\"      \n##  [46] \"r_gwcode[352,Intercept]\"       \"r_gwcode[355,Intercept]\"       \"r_gwcode[359,Intercept]\"      \n##  [49] \"r_gwcode[360,Intercept]\"       \"r_gwcode[365,Intercept]\"       \"r_gwcode[366,Intercept]\"      \n##  [52] \"r_gwcode[367,Intercept]\"       \"r_gwcode[368,Intercept]\"       \"r_gwcode[369,Intercept]\"      \n##  [55] \"r_gwcode[370,Intercept]\"       \"r_gwcode[371,Intercept]\"       \"r_gwcode[372,Intercept]\"      \n##  [58] \"r_gwcode[373,Intercept]\"       \"r_gwcode[404,Intercept]\"       \"r_gwcode[411,Intercept]\"      \n##  [61] \"r_gwcode[420,Intercept]\"       \"r_gwcode[432,Intercept]\"       \"r_gwcode[433,Intercept]\"      \n##  [64] \"r_gwcode[434,Intercept]\"       \"r_gwcode[435,Intercept]\"       \"r_gwcode[436,Intercept]\"      \n##  [67] \"r_gwcode[437,Intercept]\"       \"r_gwcode[438,Intercept]\"       \"r_gwcode[439,Intercept]\"      \n##  [70] \"r_gwcode[450,Intercept]\"       \"r_gwcode[451,Intercept]\"       \"r_gwcode[452,Intercept]\"      \n##  [73] \"r_gwcode[461,Intercept]\"       \"r_gwcode[471,Intercept]\"       \"r_gwcode[475,Intercept]\"      \n##  [76] \"r_gwcode[481,Intercept]\"       \"r_gwcode[482,Intercept]\"       \"r_gwcode[484,Intercept]\"      \n##  [79] \"r_gwcode[490,Intercept]\"       \"r_gwcode[500,Intercept]\"       \"r_gwcode[501,Intercept]\"      \n##  [82] \"r_gwcode[510,Intercept]\"       \"r_gwcode[516,Intercept]\"       \"r_gwcode[517,Intercept]\"      \n##  [85] \"r_gwcode[520,Intercept]\"       \"r_gwcode[522,Intercept]\"       \"r_gwcode[530,Intercept]\"      \n##  [88] \"r_gwcode[531,Intercept]\"       \"r_gwcode[540,Intercept]\"       \"r_gwcode[541,Intercept]\"      \n##  [91] \"r_gwcode[551,Intercept]\"       \"r_gwcode[552,Intercept]\"       \"r_gwcode[553,Intercept]\"      \n##  [94] \"r_gwcode[560,Intercept]\"       \"r_gwcode[565,Intercept]\"       \"r_gwcode[570,Intercept]\"      \n##  [97] \"r_gwcode[571,Intercept]\"       \"r_gwcode[572,Intercept]\"       \"r_gwcode[580,Intercept]\"      \n## [100] \"r_gwcode[581,Intercept]\"       \"r_gwcode[590,Intercept]\"       \"r_gwcode[600,Intercept]\"      \n## [103] \"r_gwcode[615,Intercept]\"       \"r_gwcode[616,Intercept]\"       \"r_gwcode[620,Intercept]\"      \n## [106] \"r_gwcode[625,Intercept]\"       \"r_gwcode[626,Intercept]\"       \"r_gwcode[630,Intercept]\"      \n## [109] \"r_gwcode[640,Intercept]\"       \"r_gwcode[645,Intercept]\"       \"r_gwcode[651,Intercept]\"      \n## [112] \"r_gwcode[652,Intercept]\"       \"r_gwcode[660,Intercept]\"       \"r_gwcode[663,Intercept]\"      \n## [115] \"r_gwcode[666,Intercept]\"       \"r_gwcode[670,Intercept]\"       \"r_gwcode[678,Intercept]\"      \n## [118] \"r_gwcode[690,Intercept]\"       \"r_gwcode[692,Intercept]\"       \"r_gwcode[694,Intercept]\"      \n## [121] \"r_gwcode[696,Intercept]\"       \"r_gwcode[698,Intercept]\"       \"r_gwcode[700,Intercept]\"      \n## [124] \"r_gwcode[701,Intercept]\"       \"r_gwcode[702,Intercept]\"       \"r_gwcode[703,Intercept]\"      \n## [127] \"r_gwcode[704,Intercept]\"       \"r_gwcode[705,Intercept]\"       \"r_gwcode[710,Intercept]\"      \n## [130] \"r_gwcode[712,Intercept]\"       \"r_gwcode[731,Intercept]\"       \"r_gwcode[732,Intercept]\"      \n## [133] \"r_gwcode[750,Intercept]\"       \"r_gwcode[760,Intercept]\"       \"r_gwcode[770,Intercept]\"      \n## [136] \"r_gwcode[771,Intercept]\"       \"r_gwcode[775,Intercept]\"       \"r_gwcode[780,Intercept]\"      \n## [139] \"r_gwcode[790,Intercept]\"       \"r_gwcode[800,Intercept]\"       \"r_gwcode[811,Intercept]\"      \n## [142] \"r_gwcode[812,Intercept]\"       \"r_gwcode[816,Intercept]\"       \"r_gwcode[820,Intercept]\"      \n## [145] \"r_gwcode[830,Intercept]\"       \"r_gwcode[840,Intercept]\"       \"r_gwcode[850,Intercept]\"      \n## [148] \"r_gwcode[860,Intercept]\"       \"r_gwcode[910,Intercept]\"       \"r_gwcode[940,Intercept]\"      \n## [151] \"r_gwcode[950,Intercept]\"       \"r_gwcode[40,year_c]\"           \"r_gwcode[41,year_c]\"          \n## [154] \"r_gwcode[42,year_c]\"           \"r_gwcode[51,year_c]\"           \"r_gwcode[52,year_c]\"          \n## [157] \"r_gwcode[70,year_c]\"           \"r_gwcode[90,year_c]\"           \"r_gwcode[91,year_c]\"          \n## [160] \"r_gwcode[92,year_c]\"           \"r_gwcode[93,year_c]\"           \"r_gwcode[94,year_c]\"          \n## [163] \"r_gwcode[95,year_c]\"           \"r_gwcode[100,year_c]\"          \"r_gwcode[101,year_c]\"         \n## [166] \"r_gwcode[110,year_c]\"          \"r_gwcode[130,year_c]\"          \"r_gwcode[135,year_c]\"         \n## [169] \"r_gwcode[140,year_c]\"          \"r_gwcode[145,year_c]\"          \"r_gwcode[150,year_c]\"         \n## [172] \"r_gwcode[155,year_c]\"          \"r_gwcode[160,year_c]\"          \"r_gwcode[165,year_c]\"         \n## [175] \"r_gwcode[235,year_c]\"          \"r_gwcode[290,year_c]\"          \"r_gwcode[310,year_c]\"         \n## [178] \"r_gwcode[316,year_c]\"          \"r_gwcode[317,year_c]\"          \"r_gwcode[339,year_c]\"         \n## [181] \"r_gwcode[341,year_c]\"          \"r_gwcode[343,year_c]\"          \"r_gwcode[344,year_c]\"         \n## [184] \"r_gwcode[345,year_c]\"          \"r_gwcode[346,year_c]\"          \"r_gwcode[347,year_c]\"         \n## [187] \"r_gwcode[349,year_c]\"          \"r_gwcode[352,year_c]\"          \"r_gwcode[355,year_c]\"         \n## [190] \"r_gwcode[359,year_c]\"          \"r_gwcode[360,year_c]\"          \"r_gwcode[365,year_c]\"         \n## [193] \"r_gwcode[366,year_c]\"          \"r_gwcode[367,year_c]\"          \"r_gwcode[368,year_c]\"         \n## [196] \"r_gwcode[369,year_c]\"          \"r_gwcode[370,year_c]\"          \"r_gwcode[371,year_c]\"         \n## [199] \"r_gwcode[372,year_c]\"          \"r_gwcode[373,year_c]\"          \"r_gwcode[404,year_c]\"         \n## [202] \"r_gwcode[411,year_c]\"          \"r_gwcode[420,year_c]\"          \"r_gwcode[432,year_c]\"         \n## [205] \"r_gwcode[433,year_c]\"          \"r_gwcode[434,year_c]\"          \"r_gwcode[435,year_c]\"         \n## [208] \"r_gwcode[436,year_c]\"          \"r_gwcode[437,year_c]\"          \"r_gwcode[438,year_c]\"         \n## [211] \"r_gwcode[439,year_c]\"          \"r_gwcode[450,year_c]\"          \"r_gwcode[451,year_c]\"         \n## [214] \"r_gwcode[452,year_c]\"          \"r_gwcode[461,year_c]\"          \"r_gwcode[471,year_c]\"         \n## [217] \"r_gwcode[475,year_c]\"          \"r_gwcode[481,year_c]\"          \"r_gwcode[482,year_c]\"         \n## [220] \"r_gwcode[484,year_c]\"          \"r_gwcode[490,year_c]\"          \"r_gwcode[500,year_c]\"         \n## [223] \"r_gwcode[501,year_c]\"          \"r_gwcode[510,year_c]\"          \"r_gwcode[516,year_c]\"         \n## [226] \"r_gwcode[517,year_c]\"          \"r_gwcode[520,year_c]\"          \"r_gwcode[522,year_c]\"         \n## [229] \"r_gwcode[530,year_c]\"          \"r_gwcode[531,year_c]\"          \"r_gwcode[540,year_c]\"         \n## [232] \"r_gwcode[541,year_c]\"          \"r_gwcode[551,year_c]\"          \"r_gwcode[552,year_c]\"         \n## [235] \"r_gwcode[553,year_c]\"          \"r_gwcode[560,year_c]\"          \"r_gwcode[565,year_c]\"         \n## [238] \"r_gwcode[570,year_c]\"          \"r_gwcode[571,year_c]\"          \"r_gwcode[572,year_c]\"         \n## [241] \"r_gwcode[580,year_c]\"          \"r_gwcode[581,year_c]\"          \"r_gwcode[590,year_c]\"         \n## [244] \"r_gwcode[600,year_c]\"          \"r_gwcode[615,year_c]\"          \"r_gwcode[616,year_c]\"         \n## [247] \"r_gwcode[620,year_c]\"          \"r_gwcode[625,year_c]\"          \"r_gwcode[626,year_c]\"         \n## [250] \"r_gwcode[630,year_c]\"          \"r_gwcode[640,year_c]\"          \"r_gwcode[645,year_c]\"         \n## [253] \"r_gwcode[651,year_c]\"          \"r_gwcode[652,year_c]\"          \"r_gwcode[660,year_c]\"         \n## [256] \"r_gwcode[663,year_c]\"          \"r_gwcode[666,year_c]\"          \"r_gwcode[670,year_c]\"         \n## [259] \"r_gwcode[678,year_c]\"          \"r_gwcode[690,year_c]\"          \"r_gwcode[692,year_c]\"         \n## [262] \"r_gwcode[694,year_c]\"          \"r_gwcode[696,year_c]\"          \"r_gwcode[698,year_c]\"         \n## [265] \"r_gwcode[700,year_c]\"          \"r_gwcode[701,year_c]\"          \"r_gwcode[702,year_c]\"         \n## [268] \"r_gwcode[703,year_c]\"          \"r_gwcode[704,year_c]\"          \"r_gwcode[705,year_c]\"         \n## [271] \"r_gwcode[710,year_c]\"          \"r_gwcode[712,year_c]\"          \"r_gwcode[731,year_c]\"         \n## [274] \"r_gwcode[732,year_c]\"          \"r_gwcode[750,year_c]\"          \"r_gwcode[760,year_c]\"         \n## [277] \"r_gwcode[770,year_c]\"          \"r_gwcode[771,year_c]\"          \"r_gwcode[775,year_c]\"         \n## [280] \"r_gwcode[780,year_c]\"          \"r_gwcode[790,year_c]\"          \"r_gwcode[800,year_c]\"         \n## [283] \"r_gwcode[811,year_c]\"          \"r_gwcode[812,year_c]\"          \"r_gwcode[816,year_c]\"         \n## [286] \"r_gwcode[820,year_c]\"          \"r_gwcode[830,year_c]\"          \"r_gwcode[840,year_c]\"         \n## [289] \"r_gwcode[850,year_c]\"          \"r_gwcode[860,year_c]\"          \"r_gwcode[910,year_c]\"         \n## [292] \"r_gwcode[940,year_c]\"          \"r_gwcode[950,year_c]\"          \"lprior\"                       \n## [295] \"lp__\"                          \"accept_stat__\"                 \"treedepth__\"                  \n## [298] \"stepsize__\"                    \"divergent__\"                   \"n_leapfrog__\"                 \n## [301] \"energy__\"\n```\n:::\n\n\n- 142 country-specific intercept offsets: $b_{0_j}$\n- 142 country-specific offsets to the `year_c` slope: $b_{1_j}$\n- 2 global terms (intercept and `year_c`) for the $\\mu$ part of the model: $\\beta_0$ and $\\beta_1$\n- 3 global terms (intercept, `year_c`, and `year_c_E2`) for the zero-inflated $\\pi$ part of the model: $\\gamma_0$ and $\\gamma_1$\n- The overall within-country $\\phi$: $\\phi_y$\n- The variability in country-specific intercept and slope offsets: $\\sigma^2_0$ and $\\sigma^2_1$\n- The correlation between country-specific slopes and intercepts: $\\rho$\n- 8 auxiliary Stan-specific things like `lprior`, `n_leapfrog__`, `energy__`, etc.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nm_purpose_prelim_time_only_total$model\n##  Family: zero_inflated_beta \n##   Links: mu = logit; phi = identity; zi = logit \n## Formula: prop_contentious_trunc ~ year_c + (1 + year_c | gwcode) \n##          zi ~ year_c + I(year_c^2)\n##    Data: dat (Number of observations: 3293) \n##   Draws: 4 chains, each with iter = 5000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 16000\n## \n## Group-Level Effects: \n## ~gwcode (Number of levels: 142) \n##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)             0.51      0.04     0.43     0.60 1.00     3773     6609\n## sd(year_c)                0.03      0.01     0.03     0.05 1.00     3499     6555\n## cor(Intercept,year_c)     0.21      0.13    -0.06     0.46 1.00     6667     9619\n## \n## Population-Level Effects: \n##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept       -2.62      0.05    -2.72    -2.52 1.00     3019     5759\n## zi_Intercept    -2.43      0.09    -2.60    -2.26 1.00    18250    12967\n## zi_year_c       -0.07      0.01    -0.08    -0.05 1.00    22613    12673\n## zi_Iyear_cE2     0.01      0.00     0.01     0.02 1.00    17721    13086\n## year_c           0.06      0.00     0.05     0.07 1.00     7034     9936\n## \n## Family Specific Parameters: \n##     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## phi    10.99      0.35    10.33    11.68 1.00    13480    11770\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nAs we did with the hurdle model previously, we'll walk through all these different population-level (or global within-country) effects, group level (between-country) effects, and within- and between-country variability. We'll also look at effects at each part of the model—the regular part that models $\\mu$ and the zero-inflated part that models $\\pi$.\n\n\n### Non-zero-inflated vs. zero-inflated parts (µ vs. π)\n\nLike the hurdled model, we have three different parts of the model to work with:\n\n$$\n\\begin{aligned}\n\\text{Proportion}_{it_j} &\\sim \\operatorname{Zero-inflated\\, Beta}(\\pi_{it}, \\mu_{it_j}, \\phi_y) & \\text{Proportion} \\\\\n\\operatorname{logit}(\\pi_{it}) &= \\gamma_0 + \\gamma_1 \\text{Year}_{it} + \\gamma_2 \\text{Year}^2_{it} & \\text{on/off process} \\\\\n\\operatorname{logit}(\\mu_{it_j}) &= (\\beta_0 + b_{0_j}) + (\\beta_1 + b_{1_j}) \\text{Year}_{it_j} & \\text{$\\geq 0$ process}\n\\end{aligned}\n$$\n\nAnd like we did with the hurdle model previously (and like [I illustrate in my guide here](https://www.andrewheiss.com/blog/2022/09/26/guide-visualizing-types-posteriors/)), we can use different combinations of `linpred_draws()`, `epred_draws()`, and `predicted_draws()` to explore different aspects of these parts' posterior distributions.\n\n#### Zero part (π and γs)\n\nFirst we'll look at the on/off process, or $\\operatorname{logit}(\\pi_{it})$. This is conceptually different from the hurdle process, which predicts if an outcome is 0 or not 0. With zero-inflation, we're predicting if the data-generating process is on or not—but the data-generating process can still result in 0s, theoretically. Recall the monk example from *Statistical Rethinking* [mentioned above](#hurdle-vs.-zero-inflated-models)—monks could transcribe 0 manuscripts because the whole transcription process is \"off\" and they do no work, or they could transcribe 0 manuscripts because they work really really slowly or are lazy, etc.\n\nIn this part of model, we used year and year², so we have a $\\gamma_0$ coefficient for the intercept and $\\gamma_1$ and $\\gamma_2$ coefficients for the year effect. Theese are on the logit scale, so exponentiating them will give us an odds ratio, while inverse logit-ing them with `plogis()` will give us probabilities. \n\nImportantly, because we're working with polynomials, we can't really just interpret the $\\gamma_1$ and $\\gamma_2$ year coefficients—they move together and influence the year effect simultaneously. They lead to a non-linear slope across the range of possible years. To see the year effect, then, we need to look at partial derivatives or marginal effects.\n\n\n\n\n\nHere are the zero-inflated coefficients as log odds. We won't exponentiate them because (1) an exponentiated value doesn't make sense for an intercept, and (2) there are two year coefficients that work together, so we can't interpret just one of the values.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\n# Uninterpretable log odds\nm_purpose_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\") %>% \n  filter(component == \"zi\")\n## # A tibble: 3 × 7\n##   effect component term        estimate std.error conf.low conf.high\n##   <chr>  <chr>     <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  zi        (Intercept)  -2.43     0.0875   -2.60     -2.26  \n## 2 fixed  zi        year_c       -0.0651   0.00727  -0.0793   -0.0508\n## 3 fixed  zi        Iyear_cE2     0.0129   0.00115   0.0107    0.0152\n```\n:::\n\n\nTo make the log odds intercept value (-2.62)  more interpretable, we can convert it to a probability with $\\frac{e^{\\gamma_0}}{1 + e^{\\gamma_0}}$, or `plogis()`, which is 0.068, which means that in the year 2000 (i.e. when `year_c` is 0), the model predicts that 6.8% of countries received 0 contentious aid. \n\nWe can confirm with a plot, which also helps set the stage for interpreting the year effect. In 2000 the predicted proportion is indeed 6.8%.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_zi_zi <- m_purpose_prelim_time_only_total$model %>% \n  linpred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n                re_formula = NA,\n                dpar = \"zi\", transform = TRUE) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = zi)) +\n  stat_lineribbon(color = clrs$Emrld[7], alpha = 0.3) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = clrs$Emrld[2:4]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted proportion\\nof countries receiving\\n0% contentious aid\",\n       subtitle = \"Predicted global proportion of countries receiving 0% contentious aid, π only\") +\n  theme_donors()\n\nplot_zi_zi_lines <- plot_zi_zi +\n  geom_vline(xintercept = c(1992, 2000, 2010),\n             linewidth = 0.25, linetype = \"21\")\n\nplot_actual_zeros <- df_country_aid_laws %>% \n  group_by(year) %>% \n  summarize(prop_zero = sum(prop_contentious == 0) / n()) %>% \n  ggplot(aes(x = year, y = prop_zero)) + \n  geom_line(color = clrs$Emrld[5], linewidth = 1) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(x = NULL, y = \"Actual proportion of\\ncountries receiving\\n0% contentious aid\",\n       subtitle = \"Actual global proportion of countries receiving 0% contentious aid\") +\n  theme_donors()\n\n(plot_zi_zi_lines / plot_actual_zeros) &\n  coord_cartesian(ylim = c(0, 0.45))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-prop-zeros-over-time-zi-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nFor the year effect, we need to look at the slope of the line at different years, since it changes across time. As seen in the plot, pre-2002ish, it's a negative effect; after 2002ish, it's positive.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nm_purpose_prelim_time_only_total$model %>% \n  marginaleffects(newdata = datagrid(year_c = c(-8, 0, 10)),\n                  dpar = \"zi\") %>% \n  mutate(year = year_c + 2000) %>% \n  select(type, year_c, year, dydx, conf.low, conf.high, predicted)\n##       type year_c year     dydx conf.low conf.high predicted\n## 1 response     -8 1992 -0.05140 -0.06312  -0.04070    0.2537\n## 2 response      0 2000 -0.00484 -0.00596  -0.00381    0.0813\n## 3 response     10 2010  0.02374  0.01772   0.03038    0.1437\n```\n:::\n\n\nMore precisely, in 1992 the year effect is -0.051, which means that one additional year is associated with a 5.14 percentage point decrease in the proportion of 0s, on average. In 2000, there is a tiny 0.484 percentage point decrease, while in 2010 there is a more substantial 2.374 increase in the proportion of 0s.\n\n#### Non-zero part (µ ~~and βs~~)\n\nNext we'll look at the part of the model that predicts what happens when the data-generating process is on (i.e. the monks are for sure working, so how many manuscripts will they transcribe?), or $\\operatorname{logit}(\\mu_{it_j})$. In this part of model, we only used year, so we have a $\\beta_0$ coefficient for the intercept and a $\\beta_1$ coefficient for the year effect. Since this is a beta model, the coefficients are on the logit scale, so we can exponentiate them or inverse logit them to make them more interpretable. As with the hurdle model example, *technically* we can't interpret these $\\beta$ coefficients directly because of the random effects, but we'll pretend we can just for fun.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\n# Log odds\n# Uninterpretable log odds\nm_purpose_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\") %>% \n  filter(component != \"zi\")\n## # A tibble: 2 × 7\n##   effect component term        estimate std.error conf.low conf.high\n##   <chr>  <chr>     <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  cond      (Intercept)  -2.62     0.0495   -2.72     -2.52  \n## 2 fixed  cond      year_c        0.0613   0.00410   0.0534    0.0694\n\n# Exponentiated\nm_purpose_prelim_time_only_total$model %>% \n  tidy(effects = \"fixed\") %>% \n  filter(component != \"zi\") %>% \n  mutate(across(c(estimate, conf.low, conf.high), exp))\n## # A tibble: 2 × 7\n##   effect component term        estimate std.error conf.low conf.high\n##   <chr>  <chr>     <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  cond      (Intercept)   0.0729   0.0495    0.0660    0.0803\n## 2 fixed  cond      year_c        1.06     0.00410   1.05      1.07\n```\n:::\n\n\nThe intercept is nonsensical both as log odds and when exponentiated, but if we inverse logit its log odds with `plogis()`, we get 0.068, which means that in 2000, the predicted average proportion of contentious aid is 6.79%. \n\nThe exponentiated year effect is 1.063, which means that a one-year increase in time increases the likelihood of receiving additional contentious aid by 6.32%. BUT that's (1) weird to think about as \"receiving additional contentious aid\", and (2) wrong because of the multilevel nature of the model. So we won't actually put much stock in these $\\beta$ coefficients alone and save the more substantive interpretation of the year effect for the next section in this guide on conditional and marginal effects.\n\nInstead of thinking about percent changes and log odds, we can look at predictions on the percentage point scale, which is far more intuitive. We can extract predictions from the $\\operatorname{logit}(\\mu_{it_j})$ part of the model with `linpred_draws()`. As before, with `transform = FALSE` we'll get logit-scale values; with `transform = TRUE` we'll get percentage points.\n\nThe predicted value in 2000 is 6.79%, as expected. The line goes up every year, also as expected. We don't know how much it goes up at each year yet—we're purposely holding off on finding the year effect until later so we can find conditional and marginal effects.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_zi_mu_linpred <- m_purpose_prelim_time_only_total$model %>% \n  linpred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n                re_formula = NA, dpar = \"mu\") %>% \n  mutate(.linpred = exp(.linpred)) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .linpred)) +\n  stat_lineribbon(color = clrs$PurpOr[7], alpha = 0.3) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = clrs$PurpOr[3:5]) +\n  coord_cartesian(ylim = c(0, 0.20)) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted percentage of\\ncontentious aid\",\n       subtitle = \"Predicted global average proportion of contentious aid, µ only\") +\n  theme_donors()\nplot_zi_mu_linpred\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-linpred-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n#### Combined processes (*y*)\n\nFinally, we can look at both parts of the model simultaneously. The outcome is a function of both the $\\pi$ part and the $\\mu$ part:\n\n$$\n\\text{Proportion}_{it_j} \\sim \\operatorname{Zero-inflated\\, Beta}(\\pi_{it}, \\mu_{it_j}, \\phi_y)\n$$\nWe can work with both of these parts at the same time if we `epred_draws()` instead of `linpred_draws()`, which calculates the expectation (the \"e\" in epred) of the posterior predictive distribution of the outcome, or $\\textbf{E}(\\text{Proportion}_{it_j})$.\n\nThe plot of epred values is different from the linear predictor we found with the $\\mu$ part only—that's because we're now also incorporating the on/off process. This is actually really pretty neat! The epred values are lower than the linpred values in earlier years, since there's a higher proportion of 0s in the $\\pi$ part of the model then. Similarly, the epred trend flattens out completely after 2010 because the high proportion of 0s from $\\pi$ balances out the the year effect in $\\mu$. Magical mixture models!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_zi_epred <- m_purpose_prelim_time_only_total$model %>% \n  epred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n              re_formula = NA) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .epred)) +\n  stat_lineribbon(color = clrs$Peach[7], alpha = 0.3) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = clrs$Peach[3:5]) +\n  coord_cartesian(ylim = c(0, 0.20)) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted percentage of\\ncontentious aid\",\n       subtitle = \"Predicted global average proportion of contentious aid, both µ and π\") +\n  theme_donors()\nplot_zi_epred\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-epred-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nHere's what all three of these plots look like at the same time—just the $\\pi$ zero-inflated is-the-system-on-or-off part, just the $\\mu$ when-the-system-is-on part, and the combined epred part:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(plot_zi_zi / plot_zi_mu_linpred / plot_zi_epred) +\n  plot_annotation(title = \"Conditional effect of time on proportion of contentious aid\",\n                  subtitle = \"prop_contentious ~ year + (1 + year | country)\\nzi ~ year + I(year^2)\",\n                  theme = theme(plot.title = element_text(family = \"Inter\", face = \"bold\"),\n                                plot.subtitle = element_text(family = \"Inconsolata\")))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-all-parts-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n### Global analysis (βs)\n\nWe just looked at the intercept and year effect above, but as with the hurdle models, these are technically incorrect because we used a multilevel model and haven't dealt with the $b_{0_j}$ $b_{1_j}$ offsets in the intercept and slope.\n\nInstead, we need to look at a specific flavor of statistical effect or estimand—one of these:\n\n- **Conditional effect = average country**: All $b_n$ offsets are set to 0 so that the effects or coefficients represent the effect in a typical country with the global average level of a variable.\n- **Marginal effect = countries on average**: All $b_n$ offsets are dealt with mathematically (averaged/marginalized out or integrated out) so that the effects or coefficients represent the effect of a variable across all countries on average.\n\nAgain, we're generally more interested in conditional effects, but we'll look at both here just for reference.\n\n#### Conditional effects\n\nThe effect we care about here is the instantaneous slope/partial derivative of year. Rather than figure out the formal calculus for that, we'll use `marginaleffects()` to calculate the numerical derivative, which finds the predicted value of $Y$ at some value of $X$, finds the predicted value of $Y$ at some value of $X$ plus a tiny bit ($\\varepsilon$ here), subtracts them, and divides by $\\varepsilon$. For our situation here, it looks like this mess:\n\n$$\n\\frac{\\textbf{E}(\\text{Proportion}_{i_j} \\mid \\{b_{0_j}, b_{0_j}\\} = 0, \\text{Year} = t + \\varepsilon) - \\textbf{E}(\\text{Proportion}_{i_j} \\mid \\{b_{0_j}, b_{0_j}\\} = 0, \\text{Year} = t)}{\\varepsilon}\n$$\n\nAgain, {brms}'s syntax for $\\{b_{0_j}, b_{0_j}\\} = 0$ (i.e. setting all the random offsets to zero) is to use `re_formula = NA` in the different functions that generate predictions.\n\nTo see what this estimand looks like, it's helpful to first look at range of predicted values of the proportion of contentious aid so we can see what line we're finding the slope for. To help with the intuition we'll look at the plots on both the link (logid) scale and the back-transformed response (percentage point) scale.\n\nWe can do this automatically with `marginaleffects::plot_cap()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\n# Log scale\nplot_cap(m_purpose_prelim_time_only_total$model, \n         condition = \"year_c\", type = \"link\", \n         re_formula = NA)\n\n# Dollar scale\nplot_cap(m_purpose_prelim_time_only_total$model, \n         condition = \"year_c\", type = \"response\", \n         re_formula = NA)\n```\n:::\n\n\nOr more manually with `epred_draws()`:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\npreds_logit_zi <- m_purpose_prelim_time_only_total$model %>% \n  linpred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n                re_formula = NA) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .linpred)) +\n  stat_lineribbon(color = clrs$Peach[7]) +\n  scale_fill_manual(values = clrs$Peach[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted proportion of\\ncontentious foreign aid, logit scale\") +\n  theme_donors()\n\npreds_prop_zi <- m_purpose_prelim_time_only_total$model %>% \n  epred_draws(newdata = tibble(year_c = seq(-10, 13, 1)),\n              re_formula = NA) %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = .epred)) +\n  stat_lineribbon(color = clrs$Peach[7]) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = clrs$Peach[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Predicted proportion of\\ncontentious foreign aid\") +\n  theme_donors()\n\npreds_logit_zi | preds_prop_zi\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-conditional-predictions-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nThe slopes of both of these lines are actually fairly straight. On the log scale, the slope is constant and linear; on the dollar scale, the slope is generally pretty constant, though it starts to think about leveling out a tiny bit after 2010 because of the increased probability of 0s.\n\nWe can use `marginaleffects()` to get the exact slope of those lines at any value of `year_c` that we want, and we can plot those slopes across the whole range of years. On the logit scale, the line is flat, since the slope is constant; on the proportion scale, it is generally flat until right after 2005 when it takes a sharp downturn, representing the flattening of the curve. Note that the logit-scale conditional effect is flat, while the proportion scale effect is all weird and drops off quickly. In theory these two plots should look the same. The difference is because {marginaleffects} uses epred values when you specify `type = \"response\"`, which means that the proportion-scale conditional effect incorporates the zero-process. When we specify `type = \"link\"`, we get logit-scale effects, but those **don't** incorporate the zero process because {marginaleffects} uses linpred values.\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/calculate-conditional-mfx-zi_b786794573806083b52e6ca7cb2da4d2'}\n\n```{.r .cell-code}\nmfx_logit_zi <- marginaleffects(\n  m_purpose_prelim_time_only_total$model, \n  newdata = datagrid(year_c = seq(-10, 13, by = 1)),\n  variables = \"year_c\",\n  type = \"link\",\n  re_formula = NA\n)\n\nmfx_prop_zi <- marginaleffects(\n  m_purpose_prelim_time_only_total$model, \n  newdata = datagrid(year_c = seq(-10, 13, by = 1)),\n  variables = \"year_c\",\n  type = \"response\",\n  re_formula = NA\n)\n```\n:::\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_mfx_logit_zi <- mfx_logit_zi %>% \n  posteriordraws() %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = exp(draw))) +\n  stat_lineribbon(color = clrs$PurpOr[7]) +\n  scale_fill_manual(values = clrs$PurpOr[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Conditional effect (logit)\") +\n  theme_donors()\n\nplot_mfx_prop_zi <- mfx_prop_zi %>% \n  posteriordraws() %>% \n  mutate(year = year_c + 2000) %>% \n  ggplot(aes(x = year, y = draw)) +\n  stat_lineribbon(color = clrs$PurpOr[7]) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = clrs$PurpOr[1:3]) +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Conditional effect (percentage points)\") +\n  theme_donors()\n\nplot_mfx_logit_zi | plot_mfx_prop_zi\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-conditional-mfx-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nTo help even more with the intuition, here are the exact slopes (or conditional effects) at 1990, 2000, 2010, and 2012, both on the logit scale and the percentage point (pp) scale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_logit_zi_small <- mfx_logit_zi %>% \n  filter(year_c %in% c(-10, 0, 10, 12)) %>% \n  mutate(year = 2000 + year_c) %>% \n  select(year, dydx, conf.low, conf.high)\n\nmfx_prop_zi_small <- mfx_prop_zi %>% \n  filter(year_c %in% c(-10, 0, 10, 12)) %>% \n  mutate(year = 2000 + year_c) %>% \n  select(year, dydx, conf.low, conf.high) %>% \n  mutate(across(c(dydx, conf.low, conf.high), ~label_number(scale = 100, suffix = \" pp.\")(.)))\n\nmfx_logit_zi_small\n##   year   dydx conf.low conf.high\n## 1 1990 0.0614   0.0535    0.0692\n## 2 2000 0.0614   0.0535    0.0692\n## 3 2010 0.0614   0.0535    0.0692\n## 4 2012 0.0614   0.0535    0.0692\nmfx_prop_zi_small\n##   year      dydx   conf.low conf.high\n## 1 1990 0.427 pp.  0.367 pp. 0.497 pp.\n## 2 2000 0.389 pp.  0.335 pp. 0.447 pp.\n## 3 2010 0.266 pp.  0.150 pp. 0.391 pp.\n## 4 2012 0.026 pp. -0.166 pp. 0.211 pp.\n```\n:::\n\n\n\n\nInterpretation time. We can look at these effects a few different ways. On the logit scale, a one-year increase in time is associated with a 0.061 increase in the proportion of contentious aid. Exponentiated beta-model effects also don't make a lot of sense (a  increase in the likelihood of some increase in the proportion? idk). \n\nWorking with the proportion/percentage point scale is a lot easier—though it varies across time. In 1990 the conditional effect of a one-year increase in time is 0.427 pp. of contentious aid, while in 2000 it is 0.389 pp. and in the flatland of 2012 it is 0.026 pp.. \n\nFor fun, here are the posteriors of these different conditional effects:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- mfx_logit_zi %>% \n  posteriordraws() %>% \n  filter(year_c == 0) %>% \n  ggplot(aes(x = draw)) +\n  stat_halfeye(fill = clrs$PurpOr[5]) +\n  labs(x = \"Conditional effect of year on the\\nproportion of contentious aid, logit scale\", \n       y = NULL, subtitle = \"Logit scale\", fill = NULL) +\n  theme_donors()\n\np2 <- mfx_prop_zi %>% \n  posteriordraws() %>% \n  filter(year_c %in% c(-10, 0, 10)) %>% \n  mutate(year = year_c + 2000) %>% \n  pivot_longer(draw) %>% \n  ggplot(aes(x = value, fill = factor(year))) +\n  stat_halfeye(alpha = 0.7) +\n  scale_x_continuous(labels = label_number(scale = 100, suffix = \" pp.\")) +\n  scale_fill_manual(values = clrs$Sunset[c(2, 4, 6)]) +\n  labs(x = \"Conditional effect of year on the\\nproportion of contentious aid, percentage points\", \n       y = NULL, subtitle = \"Proportion / percentage point scale\", fill = NULL) +\n  theme_donors()\n\n(p1 | p2) + \n  plot_annotation(title = \"Conditional effect of year on proportion of contentious aid for a typical country\",\n                  theme = theme(plot.title = element_text(family = \"Inter\", face = \"bold\")))\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-zi-conditional-mfx-all-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nAgain, these are all conditional effects, which means that they represent the effect of year **for a typical country**, or a country where all the country-specific offsets are 0.\n\n#### Marginal effects\n\nInstead of looking at the effect of year **in an average country** (or the *conditional effect*) by setting $\\{b_{0_j}, b_{0_j}\\} = 0$, we can look at the effect of year **in all countries on average** (or the *marginal effect*) by mathematically incorporating information about all countries' random offsets. Because we're working with a continuous treatment, our estimand is an instantaneous slope, which we calculate with the same numerical derivative approach we used earlier for the conditional effects (i.e. the difference between the effect when year is set to something and when year is set to something + a tiny amount ($\\varepsilon$), divided by $\\varepsilon$):\n\n$$\n\\frac{\\textbf{E}(\\text{Proportion}_{i_j} \\mid \\text{Year} = t + \\varepsilon) - \\textbf{E}(\\text{Proportion}_{i_j} \\mid \\text{Year} = t)}{\\varepsilon}\n$$\n\nWe can do this with `marginaleffects()` by setting `re_formula = NULL` instead of `re_formula = NA`.\n\n##### Average / marginalize / integrate across existing random effects\n\nThe first way to deal with the country-specific offsets is to average (or marginalize or integrate across—all of these mean the same thing) all the existing random effects. In practice this means calculating the instantaneous slope of `year_c` in each of the countries, then collapsing those estimates into one average.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_logit_marginal_zi <- marginaleffects(\n  m_purpose_prelim_time_only_total$model, \n  newdata = datagrid(gwcode = unique),\n  variables = \"year_c\",\n  type = \"link\",\n  re_formula = NULL\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_logit_marginal_zi %>% tidy()\n##   type   term estimate conf.low conf.high\n## 1 link year_c   0.0613   0.0556    0.0668\n```\n:::\n\n\n##### Integrate out random effects\n\nThe second way to deal with the random effects is to invent a bunch of hypothetical countries that all have different simulated country-specific offsets based on the distributions of $\\sigma_0$ and $\\sigma_1$, and then calculate the instantaneous slope in each of those fake countries, *and then* collapse those country-specific slopes into one average. This is the equivalent of *integrating out* the random effects. Here we'll invent 200 fake countries:\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/calculate-marginal-zi-integrated-out_87dd49f3d71178b636cea7ede15f7e80'}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_logit_marginal_zi_int <- marginaleffects(\n  m_purpose_prelim_time_only_total$model, \n  variables = \"year_c\",\n  newdata = datagrid(gwcode = c(-1:-200)),\n  re_formula = NULL,\n  allow_new_levels = TRUE,\n  sample_new_levels = \"gaussian\",\n  type = \"link\"\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nmfx_logit_marginal_zi_int %>% tidy()\n##   type   term estimate conf.low conf.high\n## 1 link year_c   0.0614   0.0523    0.0707\n```\n:::\n\n\n##### Comparing the two\n\nAs with the hurdle model, since we have so many countries (142 real ones vs. 200 fake ones), the estimates are basically the same. If we were working with fewer real countries, the estimates from the average / marginalize / integrate across approach would be less accurate.\n\nWhile the posterior means are the same, the integrating out approach has a little more uncertainty associated with it:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_marginal_zi <- mfx_logit_marginal_zi %>% \n  posteriordraws() %>% \n  group_by(type, term, drawid) %>% \n  summarize(draw = mean(draw))\n\ndata_int_zi <- mfx_logit_marginal_zi_int %>% \n  posteriordraws() %>% \n  group_by(type, term, drawid) %>% \n  summarize(draw = mean(draw))\n\nplot_marginal_zi_mfx_both <- ggplot(mapping = aes(x = draw)) +\n  stat_halfeye(data = data_int_zi, aes(fill = \"Integrated out\")) +\n  stat_halfeye(data = data_marginal_zi, aes(fill = \"Averaged across\"), \n               slab_color = \"white\", slab_linewidth = 0.5) +\n  scale_fill_manual(values = clrs$Peach[c(2, 5)]) +\n  # coord_cartesian(xlim = c(1, 1.06)) +\n  labs(x = \"Marginal effect of year on\\nproportion of contentious aid, logit scale\", y = NULL,\n       fill = \"Random effect marginalizing method\",\n       title = \"Marginal marginal effects\",\n       subtitle = \"Effect of year on proportion of contentious aid across all countries on average\") +\n  theme_donors()\nplot_marginal_zi_mfx_both\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-marginal-mfx-both-zi-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n### Country-specific analysis (*b* offsets and ρ)\n\nThere are 142 different countries, each with their own intercept offsets and slope offsets, so I won't plot them here. We can look at the first few of these different country-specific offsets to help with the intuition. Each country's random effects are $b_0$ and $b_1$. These offsets get added to the global averages $\\beta_0$ and $\\beta_1$, giving each country its own unique slope and intercept.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nm_purpose_prelim_time_only_total$model %>%  \n  spread_draws(b_Intercept, b_year_c, r_gwcode[gwcode, term]) %>%  \n  pivot_wider(names_from = \"term\", values_from = r_gwcode) %>%  \n  mutate(country_intercept = b_Intercept + Intercept,\n         country_year_slope = b_year_c + year_c) %>%  \n  group_by(gwcode) %>%  \n  summarize(across(c(b_Intercept, Intercept, country_intercept, \n                     b_year_c, year_c, country_year_slope), \n                   ~median(.))) %>% \n  rename(`β0` = b_Intercept, `b0 offset` = Intercept, \n         `Intercept` = country_intercept,\n         `β1` = b_year_c, `b1 offset` = year_c,\n         `Year slope` = country_year_slope)\n## # A tibble: 142 × 7\n##    gwcode    β0 `b0 offset` Intercept     β1 `b1 offset` `Year slope`\n##     <int> <dbl>       <dbl>     <dbl>  <dbl>       <dbl>        <dbl>\n##  1     40 -2.62      0.416      -2.20 0.0612    0.0240         0.0852\n##  2     41 -2.62      0.755      -1.86 0.0612   -0.0277         0.0336\n##  3     42 -2.62     -0.0129     -2.63 0.0612    0.00232        0.0636\n##  4     51 -2.62      0.222      -2.40 0.0612    0.0310         0.0923\n##  5     52 -2.62     -0.611      -3.23 0.0612    0.0210         0.0823\n##  6     70 -2.62     -0.578      -3.20 0.0612    0.00786        0.0692\n##  7     90 -2.62      0.853      -1.77 0.0612    0.00105        0.0622\n##  8     91 -2.62      0.272      -2.35 0.0612    0.000354       0.0616\n##  9     92 -2.62      0.502      -2.12 0.0612   -0.0115         0.0497\n## 10     93 -2.62      0.428      -2.19 0.0612   -0.0318         0.0294\n## # … with 132 more rows\n```\n:::\n\n\nWe can make a spaghetti plot of these country-specific offsets on the percentage point scale:\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/calculate-country-lines-zi_51a61b23faefff389c2d7d9b8e66c01c'}\n\n```{.r .cell-code}\nall_country_lines_zi <- m_purpose_prelim_time_only_total$model %>%  \n  epred_draws(expand_grid(gwcode = unique(df_country_aid_laws$gwcode),\n                            year_c = seq(-10, 13, by = 1))) %>%  \n  group_by(gwcode, year_c) %>%  \n  median_qi(.epred) %>%  \n  mutate(year = year_c + 2000)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nall_country_lines_zi %>% \n  ggplot(aes(x = year, y = .epred)) +\n  geom_line(aes(group = gwcode),\n            color = clrs$Prism[1], linewidth = 0.15) +\n  scale_y_continuous(labels = label_percent()) +\n  # scale_y_continuous(trans = log_trans(),\n  #                    labels = label_math(e^.x, format = log)) +\n  labs(x = NULL, y = \"Proportion of contentious aid\") +\n  theme_donors()\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/plot-country-lines-zi-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\nDue to the magic of multilevel models, these intercept and slope offsets are correlated with each other—we modeled the offsets from a multivariate normal distribution, and the correlation between the two $b_{n_j}$ parameters is defined by $\\rho_{0, 1}$:\n\n$$\n\\left(\n  \\begin{array}{c} \n  b_{0_j} \\\\\n  b_{1_j}\n  \\end{array}\n\\right) \n\\sim \\text{MV}\\,\\mathcal{N}\n\\left[\n  \\left(\n    \\begin{array}{c}\n    0 \\\\\n    0 \\\\\n    \\end{array}\n  \\right)\n  , \\,\n  \\left(\n  \\begin{array}{cc}\n     \\sigma^2_{0} & {\\color{red} \\rho_{0, 1}}\\, \\sigma_{0} \\sigma_{1} \\\\ \n     \\cdots & \\sigma^2_{1}\n  \\end{array}\n\\right)\n\\right]\n$$\n\nWhen $\\rho$ is negative, bigger intercepts have smaller slopes; when $\\rho$ is positive, bigger intercepts have bigger slopes. With our data, if $\\rho$ is big and positive it would imply that countries with higher baseline levels of aid contentiousness would see a larger and steeper year effect. In our actual model, $\\rho$ is slightly positive, which is neat:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_purpose_prelim_time_only_total$model %>% \n  spread_draws(cor_gwcode__Intercept__year_c) %>% \n  ggplot(aes(x = cor_gwcode__Intercept__year_c)) +\n  stat_halfeye(fill = clrs$Prism[2]) +\n  geom_vline(xintercept = 0) +\n  labs(x = \"ρ<sub>0, 1</sub>\", y = NULL) +\n  theme_donors() +\n  theme(axis.title.x = element_markdown())\n```\n\n::: {.cell-output-display}\n![](model-tricky-outcomes_files/figure-html/rho-dist-zi-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n### Within- and between-country variability (φ and σs)\n\n\n\n\n\nFinally, we can look at all the terms related to uncertainty. We have three to work with:\n\n- $\\phi_y$ (`phi`): the precision or variance of aid contentiousness within countries. On the log scale, it's 10.99, which is 59358 when unlogged or exponentiated, which is *really really* precise. To illustrate this, we can look at the distribution of the proportion of contentious aid when `year_c` is 0, or in 2000. Based on just a beta distribution with $\\mu$ and $\\phi$ (i.e. ignoring the zero-inflated part for now), we have a distribution of $\\operatorname{Beta}(0.068, 59358)$ which looks like this, very narrowly focused around the baseline average 2000 proportion:\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  beta_params <- m_purpose_prelim_time_only_total$model %>% \n    tidy(parameters = c(\"b_(Intercept)\", \"phi\"))\n  \n  beta_mu <- beta_params %>% \n    filter(term == \"b_(Intercept)\") %>% \n    pull(estimate)\n  \n  beta_phi <- beta_params %>% \n    filter(term == \"phi\") %>% \n    pull(estimate)\n  \n  ggplot() +\n    stat_function(geom = \"area\", fill = clrs$Prism[7],\n                  fun = ~dprop(., mean = plogis(beta_mu), size = exp(beta_phi))) +\n    scale_x_continuous(labels = label_percent(), limits = c(0.06, 0.08)) +\n    labs(title = \"Distribution of non-zero-inflated contentious aid in 2000\",\n         subtitle = glue::glue(\"Beta(µ = plogis({round(beta_mu, 2)}), φ = exp({round(beta_phi, 2)})) or Beta(µ = {round(plogis(beta_mu), 3)}, φ = {round(exp(beta_phi), 0)})\")) +\n    theme_donors()\n  ```\n  \n  ::: {.cell-output-display}\n  ![](model-tricky-outcomes_files/figure-html/plot-zi-phi-1.png){fig-align='center' width=90%}\n  :::\n  :::\n\n\n- $\\sigma_0$ (`sd__(Intercept)` for the `gwcode` group): the variability between countries' baseline averages, or the variability around the $b_{0_j}$ offsets. Here it's 0.51, which means that across or between countries, the proportion of contentious aid by 0.5 logit units.\n\n- $\\sigma_1$ (`sd__year_c` for the `gwcode` group): the variability between countries' year effects, or the variability around the $b_{1_j}$ offsets. Here it's 0.03, which means that average year effects vary by 0.03 logit units across or between countries.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nm_purpose_prelim_time_only_total$model %>% \n  tidy(parameters = c(\"sd_*\", \"phi\")) %>% \n  select(-component)\n## # A tibble: 3 × 5\n##   term                   estimate std.error conf.low conf.high\n##   <chr>                     <dbl>     <dbl>    <dbl>     <dbl>\n## 1 sd_gwcode__(Intercept)   0.507    0.0421    0.430     0.596 \n## 2 sd_gwcode__year_c        0.0345   0.00506   0.0253    0.0450\n## 3 phi                     11.0      0.348    10.3      11.7\n```\n:::\n\n\nLike the hurdle model, we still can’t get an ICC for the percent of variation explained by between-country differences:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"show\"}\nperformance::icc(m_purpose_prelim_time_only_total$model)\n## [1] NA\n```\n:::\n\n\nBut we can use `performance::variance_decomposition()` to get a comparable number, since it uses the posterior predictive distribution of the model to figure out the between-country variance. Between-country differences explain just 36ish% of the variation in the proportion of contentious aid, meaning that within-country differences (or time-based differences) matter a lot more in this case. That's cool.\n\n\n::: {.cell layout-align=\"center\" hash='model-tricky-outcomes_cache/html/model-prelim-icc-zi_d3e98ccbab6cffd2788bb30a8f22b33f'}\n\n```{.r .cell-code  code-fold=\"show\"}\nperformance::variance_decomposition(m_purpose_prelim_time_only_total$model)\n## # Random Effect Variances and ICC\n## \n## Conditioned on: all random effects\n## \n## ## Variance Ratio (comparable to ICC)\n## Ratio: 0.36  CI 95%: [0.24 0.47]\n## \n## ## Variances of Posterior Predicted Distribution\n## Conditioned on fixed effects: 0.01  CI 95%: [0.01 0.01]\n## Conditioned on rand. effects: 0.01  CI 95%: [0.01 0.01]\n## \n## ## Difference in Variances\n## Difference: 0.00  CI 95%: [0.00 0.01]\n```\n:::\n\n\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}